## **多线程**：
- **原子性**：指一个操作是不可中断的，即使多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰；——对于32位系统来说，对 long 类型数据的读写操作不是原子的
- **可见性**：指当一个线程修改了某一个共享变量的值，其他线程是否能够立即获取到修改之后的值；——跟 JMM 模型相关，线程私有拷贝 vs 主内存
- **有序性**：在并发时，程序的执行可能会出现乱序，这个问题是因为程序执行的时候可能会进行指令重排，重排后的指令与原指令的顺心未必一致，但对同一个线程来说，它看到的指令执行顺序一定是一致的，即指令重排会保证串行语义是一致的，但没有义务保证多线程间的语义也一致；
- 哪些指令不能重排（happen-before 原则）：
  - 4.1:一个线程内必须保证语义的串行性；
  - 4.2:volatile 原则：volatile 变量的写，必须先发生于读，这保证了 volatile 的可见性；
  - 4.3：锁规则，解锁必须发生在随后的加锁前；
  - 4.4 线程的 start 方法必须先于他每一个动作；线程所有操作先于线程的终结；线程中断（interrupt（）））必须先于被中断线程的代码执行；对象的构造函数执行，结束先于 finalize()方法；

**进程 vs 线程**\
进程是操作系统进行资源分配和调度的基本单位，是线程的容器，线程是轻量级进程，使用多线程而不是多进程去进行并发程序设计，是因为线程间的切换和调度成本远远小于进程；

**线程的状态**：
- new：新创建的线程
- runnable：通过 start 方法启动的线程，进入可运行状态
- timed-waiting：通过 wait（time）方法，等待参数指定的时间后，恢复到 runnable 状态等待被调度
- waiting：通过 wait 方法，并通过 notify（all）方法唤醒
- blocked：synchronized、io

**停止线程的优雅方法**：\
stop方法（被废弃）结束线程太简单粗暴，会直接终止线程，并立即释放这个线程持有的锁，而锁恰恰是用来维持数据一致性的，因此可能会引起数据不一致的问题；

所以，更优雅的方法有两个：
1) 通过一个volatile变量来控制线程内的循环体的退出使得线程自然结束；
2) 通过线程的interrupt（）和isInterrupted（） 方法（控制是否跳出线程内循环体）：**interrupt 不会立即中断线程**，而是给要中断的线程设置一个中断标志位，告知目标线程你要被中断了，但至于会不会起作用，得依赖目标线程是否会处理这个中断标志位，处理方法就是通过 isInterrupted 方法来判断重点标志位的值，然后根据值进行处理

方法2相比方法1的优势：如果在循环体中，出现了类似wait()或sleep()这样的操作，则只能通过中断来进行停止了，因为wait()和sleep()会响应中断，抛出InterruptedException。

### **interrupted**
线程中断的方法，但并不会使线程立即退出，而是给线程置一个标志位，目标线程自行判断决定如何处理

与线程中断有关的三个方法
1) public void interrupt();//中断线程
2) public boolean isInterrupt();//判断线程是否被中断
3) public static boolean interrupted();//判断是否被中断，并清除当前中断状态

### **wait wait（long timeout） notify notifyall**
notify会**随机唤醒**一个等待的线程，而不是先等待的线程会优先被唤醒
这两个方法必须包含在 synchronized 语句中，也即首先需要获取锁对象
这几个方法都是 object 对象的方法

### **挂起（suspend） 和 继续执行（resume）**
被废弃，因为suspend在导致线程暂停的同时，并不会去释放锁资源，其他任何线程想要访问它暂用的锁资源，都会被牵连，导致无法继续运行。只有对应的线程上执行了resume（）方法，被挂起的线程才能继续，从而所有阻塞在相关锁上的线程才可以继续执行，但是如果resume()操作意外没有执行，那么被挂起的线程可能很难有机会被执行，这样会导致占有的锁不会被释放，从而可能导致整个系统工作不正常

### **等待线程结束（join）和 谦让（yield）**
- join：一个线程的输入可能要依赖另外一个或多个线程的输出，此时，这个线程就需要等待依赖的线程执行完毕，才能继续执行，join 方法就用来实现这个目的
- yield：一旦执行，会使当前线程让出 CPU，但还是会进行 cpu 资源的争夺，但能否马上被调度执行就不一定了。如果一个线程不那么重要，或者优先级较低，而且又害怕其占用太多的 cpu 资源，那么可以在适当的时候调用这个方法，给予其他线程更多的工作机会

### **用户线程 vs 守护线程（Deamon线程）**
- 守护线程：是系统的守护者，默默在后台完成一些系统性的服务，比如GC、JIT 线程等
- 用户线程：是系统的工作线程（main 函数的执行线程就是用户线程），当一个 java 应用内，只有守护线程时，JVM 就会自动退出

### **线程池**
为什么要线程池：虽然线程是一种轻量级的工具（相比进程），但创建和关闭依然是有时间开销的，而且线程本身也要占用内存空间（虚拟机栈、程序计数器等），大量的线程可能导致OutOfMemoryError，而且大量的线程也给GC回收带来很大的压力。

#### **JDK对线程池支持的Executor框架：**
- Executor（接口）：只有一个方法void execute(Runnable command)，Executes the given command at some time in the future.  The command may execute in a new thread, in a pooled thread, or in the calling thread, at the discretion of the {@code Executor} implementation;
- ExecutorService（接口，继承Executor）： 对Executor接口进行了扩展，提供了返回 Future 对象（可以取消任务，了解任务状态-是否完成或取消，获取任务执行结果）、终止&关闭任务执行等方法。当调用 shutDown方法时，线程池会停止接受新的任务，但会完成正在 pending 中的任务。而shutDownNow方法则会立即停止当前正在执行的任务，并取消正在等待执行的任务。
- Future：可以取消任务（cancle），了解任务状态（是否完成isDone或是否取消isCalcle，任务正常完成、异常结束或被取消isDone都返回true），获取任务执行结果（get会阻塞，get(long timeout, TimeUnit unit)会等待参数指定的时间）等方法
- AbstractExecutorService（抽象类，实现ExecutorService接口）：
- ThreadPoolExecutor（具体类，继承AbstractExecutorService）：
- Executors(工具类)：类似于 Collections。提供工厂方法来创建不同类型的线程池任务调度服务；

构造ThreadPoolExecutor几个核心参数：
- corePoolSize： the number of threads to keep in the pool, even if they are idle, unless {@code allowCoreThreadTimeOut} is set；

  当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize，这个时候继续提交的任务会被保存到阻塞队列中，等待被执行。如果执行了线程池的prestartAllCoreThreads（）方法，线程池会提前创建并启动所有核心线程；

- maximumPoolSize：the maximum number of threads to allow in the pool；

  如果阻塞队列满了，且继续提交任务，则创建新的线程来执行任务，但线程总数不能超过maximumPoolSize

- keepAliveTime: when the number of threads is greater than the core, this is the maximum time that excess idle threads will wait for new tasks before terminating;

  线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间，默认情况下，该参数只有在线程数大于corePoolSize时才有用；

- workQueue: the queue to use for holding tasks before they are executed.  This queue will hold only the {@code Runnable} tasks submitted by the {@code execute} method;

  用来保存等待被执行的任务的阻塞队列，且任务必须实现Runable接口，JDK中提供了如下的阻塞队列：
  1. ArrayBlockingQueue：基于ReentrantLock实现的阻塞队列，通常用作有界队列

      当使用有界任务队列时，如果有新的任务需要执行，且线程池实际线程数量小于corePoolSize，则会优先创建新的线程来处理任务；若大于corePoolSize，则会将新的任务放入有界队列；若队列已满，则在总线程数不大于maximumPoolSize的情况下，创建新的线程执行任务。若队列已满，且总线程数已经达到maximumPoolSize，则执行拒绝策略；
应用场景：可以基于ThreadPoolExecutor来自定义实现线程池，来使用ArrayBlockingQueue来作为workqueue

  2. LinkedBlockingQueue；基于ReentrantLock实现的阻塞队列，通常用作无界队列

      与有界队列相比，除非系统资源耗尽，否则无界队列不存在任务入队失败的情况.当有新的任务到来，且线程数小于corePoolSize，则会生成新的线程来处理任务，但当线程数达到corePoolSize之后，线程数不会继续增加，新的任务如果没有空闲线程资源会不断加入队列，若任务处理速度过慢，则无界队列会迅速增长，直到耗尽系统资源；

      应用场景：Executors.newFixedThreadPool()和Executors.newSingleThreadExecutor()使用的就是无界队列

  3. SynchronousQueue：阻塞队列，无容量队列，每一个插入操作都要等待一个相应的删除操作，反之亦然；

      JDK5实现：基于ReentrantLock+queue来实现

      JDK6实现：使用了性能更好的无锁算法— 扩展的“Dual stack and Dual queue”算法，竞争机制支持公平和非公平两种：非公平竞争模式使用的数据结构是后进先出栈(Lifo Stack)；公平竞争模式则使用先进先出队列（Fifo Queue）
      
      应用场景：Executors.newCachedThreadPool（）使用的就是SynchronousQueue，其最大线程数设置的是Integer.Max_Value

  4. PriorityBlockingQueue：基于ReentrantLock实现的阻塞队列（通过notEmpty的Condition控制take阻塞，但进行扩容的操作用了spinlock，通过cas实现），可以自定义任务优先级顺序的队列（使用自然顺序（即元素实现comparable）或自定义Comparator来实现顺序），一种特殊的无界队列（不指定容量的时候默认容量是11）；数据结构使用了二叉堆（基于数组实现）；

```Java
//扩容的核心代码
private void tryGrow(Object[] array, int oldCap) {
        lock.unlock(); // must release and then re-acquire main lock
        Object[] newArray = null;
        if (allocationSpinLock == 0 &&
UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset,
                                     0, 1)) {
            try {
                int newCap = oldCap + ((oldCap < 64) ?
                                       (oldCap + 2) : // grow faster if small
                                       (oldCap >> 1));
                if (newCap - MAX_ARRAY_SIZE > 0) {    // possible overflow
                    int minCap = oldCap + 1;
                    if (minCap < 0 || minCap > MAX_ARRAY_SIZE)
                        throw new OutOfMemoryError();
                    newCap = MAX_ARRAY_SIZE;
                }
                if (newCap > oldCap && queue == array)
                    newArray = new Object[newCap];
            } finally {
                allocationSpinLock = 0;
            }
        }
        if (newArray == null) // back off if another thread is allocating
            Thread.yield();
        lock.lock();
        if (newArray != null && queue == array) {
            queue = newArray;
            System.arraycopy(array, 0, newArray, 0, oldCap);
        }
    }
```

- threadFactory: the factory to use when the executor creates a new thread;

  创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名

- RejectedExecutionHandler：the handler to use when execution is blocked because the thread bounds and queue capacities are reached；

  线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务

  RejectedExecutionHandler的几个实现策略：
  - AbortPolicy:A handler for rejected tasks that throws a RejectedExecutionException;直接抛出异常，默认策略；
  - CallerRunsPolicy：A handler for rejected tasks that runs the rejected task directly in the calling thread of the {@code execute} method;用调用者所在的线程来执行任务
  - DiscardOldestPolicy：A handler for rejected tasks that discards the oldest unhandled request and then retries {@code execute};丢弃阻塞队列中最靠前的任务，并执行当前任务；
  - DiscardPolicy：A handler for rejected tasks that silently discards the rejected task；直接丢弃任务
  
  注：当然也可以自定义饱和策略，比如记录日志或持久化存储不能处理的任务

Executors提供创建的几个线程池的区别：
- FixedThreadPool （corePoolSize=maxPoolSize=n，timeout=0s，workqueue=LinkedBlockingQueue）:

  Creates a thread pool that reuses a fixed number of threads operating off a shared unbounded queue, using the provided ThreadFactory to create new threads when needed.  At any point,at most {@code nThreads} threads will be active processing tasks.  If additional tasks are submitted when all threads are active, they will wait in the queue until a thread is available.  If any thread terminates due to a failure during execution prior to shutdown, a new one will take its place if needed to execute subsequent tasks。

  这个实例会复用 固定数量的线程 处理一个 共享的无边界队列 。任何时间点，最多有 nThreads 个线程会处于活动状态执行任务。如果当所有线程都是活动时，有多的任务被提交过来，那么它会一致在队列中等待直到有线程可用。如果任何线程在执行过程中因为错误而中止，新的线程会替代它的位置来执行后续的任务。所有线程都会一直存于线程池中，直到显式的执行 ExecutorService.shutdown() 关闭。

- CachedThreadPool（corePoolSize=0，maxPoolSize=Integer.Max_Value，timeout=60s，workqueue=SynchronousQueue）：

  Creates a thread pool that creates new threads as needed, but will reuse previously constructed threads when they are available.  These pools will typically improve the performance of programs that execute many short-lived asynchronous tasks.Calls to {@code execute} will reuse previously constructed threads if available. If no existing thread is available, a new thread will be created and added to the pool. Threads that have not been used for sixty seconds are terminated and removed from the cache. Thus, a pool that remains idle for long enough will not consume any resources。

  这个实例会根据需要，在线程可用时，重用之前构造好的池中线程。这个线程池在执行 大量短生命周期的异步任务时（many short-lived asynchronous task），可以显著提高程序性能。调用 execute 时，可以重用之前已构造的可用线程，如果不存在可用线程，那么会重新创建一个新的线程并将其加入到线程池中。如果线程超过 60 秒还未被使用，就会被中止并从缓存中移除。因此，线程池在长时间空闲后不会消耗任何资源.

- SingleThreadPool（corePoolSize=maxPoolSize=1，timeout=0s，workqueue=LinkedBlockingQueue）：

  Creates an Executor that uses a single worker thread operating off an unbounded queue. (Note however that if this single thread terminates due to a failure during execution prior to shutdown, a new one will take its place if needed to execute subsequent tasks.)  Tasks are guaranteed to execute sequentially, and no more than one task will be active at any given time. Unlike the otherwise equivalent {@code newFixedThreadPool(1)} the returned executor is guaranteed not to be reconfigurable to use additional threads.

  这个实例只会使用单个工作线程来执行一个无边界的队列。（注意，如果单个线程在执行过程中因为某些错误中止，新的线程会替代它执行后续线程）。它可以保证认为是按顺序执行的，任何时候都不会有多于一个的任务处于活动状态。和 newFixedThreadPool(1) 的区别在于，通过FinalizableDelegatedExecutorService封装了ThreadPoolExecutor，这样避免了被重新设置增加新的线程，这样保证肯定是单线程来执行任务。

#### **线程池最佳实践**
FixedThreadPool 和 CachedThreadPool 两者对高负载的应用都不是特别友好。CachedThreadPool 要比 FixedThreadPool 危险很多。
如果应用要求高负载、低延迟，最好不要选择以上两种线程池：
任务队列的无边界会导致内存溢出以及高延迟
长时间运行会导致CachedThreadPool在线程创建上失控

因为两者都不是特别友好，所以推荐使用 ThreadPoolExecutor ，它提供了很多参数可以进行细粒度的控制。
1. 将任务队列设置成有边界的队列；
2. 使用合适的 RejectionHandler - 自定义的 RejectionHandler 或 JDK 提供的默认 handler 。
3. 如果在任务完成前后需要执行某些操作，可以重载
beforeExecute(Thread, Runnable)
afterExecute(Runnable, Throwable)
4. 重载 ThreadFactory ，如果有线程定制化的需求
5. 在运行时动态控制线程池的大小（Dynamic Thread Pool）

### **Java线程模型的实现**
从JDK1.2开始，java的线程模型替换为基于操作系统原生线程模型来实现，因此，操作系统支持怎样的线程模型，在很大程度上决定了java虚拟机的线程是怎样映射的。

对Sun JDK来说，它的windows版与Linux版都是使用一对一的线程模型实现的，一条Java线程就映射到一条轻量级进程之中（对应一条内核线程），因为Windows和Linux系统提供的线程模型就是一对一的。而在Solaris平台中，由于操作系统的线程特性同时支持一对一以及多对多的线程模型，因此在Solaris版的JDK中也对应提供了两个平台专有的虚拟机参数：-XX:+UseLWPSynchronization（默认值）和-XX:+UseBoundThreads来明确指定虚拟机使用哪种线程模型

### **线程 VS 协程**
高并发下的CPU上下文切换开销
Linux进程和线程的上下文切换开销，大约是3-5us（微秒）之间。这个开销确实不算大，但是海量互联网服务端和一般的计算机程序相比，特点是：
* 高并发：每秒钟需要处理成千上万的用户请求
* 低时延：每个用户处理耗时越短越好，经常是ms级别的
* 高网络IO：经常需要从其它机器上进行网络IO、如Redis、Mysql等等
* 低计算：一般CPU密集型的计算操作并不多
即使3-5us的开销，如果上下文切换量特别大的话，也仍然会显得是有那么一些性能低下

平均每次协程切换的开销是120ns（纳秒），相对于进程切换开销大约3.5us，大约是其的三十分之一

#### **高并发下的协程内存开销**
在空间上，协程初始化创建的时候为其分配的栈内存有2KB。而线程栈要比这个数字大的多，一般都在几兆（**JAVA 线程栈内存默认1024KB**）。如果对每个用户创建一个协程去处理，100万并发用户请求只需要2G内存就够了，而如果用线程模型则需要10T

线程是操作系统中的调度器（Scheduler）来控制并发，而协程是用户自己的程序来控制并发

总结
1. 协程上下文切换开销低：协程由于是在用户态来完成上下文切换的，所以切换耗时只有区区100ns多一些，比进程切换要高30倍；
2. 协程栈内存占用小：单个协程需要的栈内存足够小，只需要2KB；
所以，协程的资源开销是非常低的，一台普通的服务器就可以支持百万协程，线程消耗的内存、线程上下文切换的开销都太大。这就限制了所能支持的并发任务的数量

### **JDK的Concurrent包（java.util.concurrent，简称juc）**

#### **Synchronized VS ReentrantLock**
1. ReentrantLock完全可以替代synchronized，在jdk5.0版本，重入锁的性能要远远好于synchronized，在jdk6.0开始，synchronized做了优化，使得两者性能差距不大；
2. 两者获得锁的线程都可以重复进入，但ReentrantLock重复进入多少次锁，就得手工释放多少次锁，如果释放次数少于进入次数，则仍然会持有锁，如果释放次数大于进入次数，则会抛出IllegalMonitorStateException；
3. ReentrantLock除了有lock方法获取锁之外，还提供了lockInterruptible()和trylock(long time,TimeUnit unit)方法，lock 方法在未获取到锁后，会一直等待锁，容易造成死锁。lockInterruptible在未获取锁的时候，可以响应中断，放弃等待锁（即在等待锁的过程中可以响应中断），trylock 在尝试 time 时间未获取锁资源后，也会放弃等待锁。这样能够尽量避免死锁的情况出现；
4. ReentrantLock提供了一个构造方法，可以通过传入参数（fair=true or false）构造一个公平锁或非公平锁，来保证等待锁的线程获取锁不是随机的，而是交替（轮询）的，而synchronized是非公平锁；
5. Synchronized和 Object.wait() 以及 Object.notify()、Object.notifyAll() 方法配合使用实现线程间的阻塞；ReentrantLock和 condition.await 和  condition.signal(All)配合使用，让线程在合适的时间进行等待，并在某个特定的时刻得到通知，继续执行。ArrayBolckingQueue 的 put 和 take操作 就利用了reentrantLock+condition;

#### **Semaphore（信号量）**
广义上来说，信号量是对锁的扩展。无论是内部锁Synchronized还是重入锁ReentrantLock，一次都只能允许一个线程访问一个共享资源，而**信号量可以指定多个线程，同时访问某个资源**

**构造信号量对象的时候，必须要指定信号量的准入数**，即同时能申请多少需求。当每个线程每次只申请一个许可时（意思是一个线程可以申请多个许可），就相当于指定了同时有多少个线程可以访问某个资源。

获得许可的方法：acquire、tryAcquire、tryAcquire(long time,TimeUnit unit)
释放许可的方法：release

#### **ReadWriteLock（读写分离锁，ReentrantReadWriteLock是其实现）**
维护了两个锁 ，一个读锁，一个写锁，读锁可以被多个读线程持有，写锁是排他的。具体实现是ReentrantReadWriteLock，获取读锁的时候实际是获取一个共享锁,需要写锁没有被hold才能获取到

读写分离锁可以有效地帮助减少锁竞争，提升系统性能。因为对于多个线程对某个资源同时进行读和写操作的情况，无论是使用内部锁（synchronized）还是可重入锁（ReentrantLock），读和读之间、读和写之间以及写和写之间都是串行操作的。但实际上读操作并不对数据的完整性造成破坏，多个线程同时读实际没必要等待锁，但考虑到数据完整性，写写操作和读写操作让然是需要相互等待和持有锁的。

所以总结来说，读写锁的访问约束如下：
- 读读：非阻塞
- 读写：阻塞
- 写读：阻塞
- 写写：阻塞

所以，如果在系统中，读操作次数远远大于写操作，则读写锁就可以发挥最大的功效，提升系统性能

#### **CountDownLatch（倒计时器）**
用来控制线程等待，可以让某个线程等待直到倒计时结束，再开始执行

CountDownLatch有两个方法是我们常用的：await()和countDown()
- await()函数用于阻塞当前线程直到CountDownLatch的计数值变为0；
- countDown()方法用于将当前CountDownLatch的计数值减1；

和 join 的区别：
join 必须等待要等待的线程全部执行完之后，才能执行。但CountDownLatch控制更灵活，**只要检测到计数器为0当前线程就可以往下执行而不用管相应的thread是否执行完毕**

#### **CyclicBarrier（循环栅栏）**
也可以实现线程间的计数等待，但功能比CountDownLatch更加复杂和强大，cyclic 意为循环，也就说**这个计数器可以反复使用**，另外，比CountDownLatch更强大的一点是，CyclicBarrier可以接受一个参数作为 barrierAction，所谓 barrierAction 就是当计数器完成一次计数后，系统会执行的动作

#### **CountDownLatch和CyclicBarrier的区别**

| CountDownLatc | CyclicBarrier |
|:-------------:|:-------------:|
|减计数方式       |加计数方式       |
|计算为0时释放所有等待的线程       |计数达到指定值时释放所有等待线程      |
|计数为0时，无法重置      |计数达到指定值时，计数置为0重新开始      |
|调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响       |调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞       |
|不可重复利用       |可重复利用      |


#### **AbstractQueueSynchronizer（AQS）：**
ReentrantLock、Semaphore、ReadWriteLock和CountDownLatch的实现基础，而AQS中实现线程的阻塞和唤醒则使用了LockSupport的park和unpark来实现

它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（CLH队列，带头结点的双向非循环链表多线程争用资源被阻塞时会进入此队列），不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。

举例：
1. ReentrantLock的实现：
实现了两个自定义同步器：FairSync（实现公平锁） 和 NonfairSync（实现非公平锁）
state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1，获取锁的方式采用的是CAS。此后，其他线程再tryAcquire()时就会失败，会被加入CLH队列并且被挂起。直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。当锁被释放之后，排在CLH队列队首的线程会被唤醒，然后CAS再次尝试获取锁。在这个时候，如果：
    1) 非公平锁：如果同时还有另一个线程进来尝试获取，那么有可能会让这个线程抢先获取；
    2) 公平锁：如果同时还有另一个线程进来尝试获取，当它发现自己不是在队首的话，就会排到队尾，由队首的线程获取到锁。

  非公平锁同步器实现：
```java
 */
        final boolean nonfairTryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0) // overflow
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
```
公平锁同步器实现：

```Java
public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }

protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &&
                    compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
```

2. CountDownLatch的实现：
任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。

### **如何在并发需要访问共享资源的情况下提升性能？**
分为有锁和无锁两种思路
1) 在必须使用锁的情况下，几个思路: 减小锁持有时间、减小锁粒度、锁分离
    - 1.1 减小锁持有时间：单个线程对锁的持有时间与系统的性能有着直接关系，如果线程持有锁的时间很长，那么锁的竞争也就越激烈，所以，应该尽可能地减少对某个锁的占有时间，以减少线程间互斥的可能。关键就是，只在必要的时候进行同步，比如，尽量用synchronized(object){}而不是直接在方法上进行synchronized；
    - 1.2 减小锁粒度：指缩小锁定对象的范围，从而减少锁冲突的可能性，进而提升系统并发能力。典型的比如ConcurrentHashMap，内部进一步细分成了若干个小的HashMap，称之为Segment（继承自ReentrantLock），默认分为16个段。因此，当增加一个元素的时候，并不是对整个map加锁，而是根据key的hashcode先判断应该放入哪个segment，然后对该segment加锁即可。如果多线程环境下同时增加元素的线程位于不同的段，则可以并行的增加元素。问题：当需要取得全局资源的时候，需要获得所有segment的锁，消耗的资源会比较多。因此，ConcurrentHashMap的size方法的性能比HashMap差。
    - 1.3 读写分离锁：读写锁（ReadWriteLock，ReentrantReadWriteLock是其实现），在读多写少的场合适用，维护了两个锁 ，一个读锁，一个写锁，读锁可以被多个读线程持有，写锁是排他的。具体实现是ReentrantReadWriteLock，获取读锁的时候实际是获取一个共享锁,需要写锁没有被hold才能获取到

      读写分离锁可以有效地帮助减少锁竞争，提升系统性能。因为对于多个线程对某个资源同时进行读和写操作的情况，无论是使用内部锁（synchronized）还是可重入锁（ReentrantLock），读和读之间、读和写之间以及写和写之间都是串行操作的。但实际上读操作并不对数据的完整性造成破坏，多个线程同时读实际没必要等待锁，但考虑到数据完整性，写写操作和读写操作让然是需要相互等待和持有锁的。

      所以总结来说，读写锁的访问约束如下：
      - 读读：非阻塞
      - 读写：阻塞
      - 写读：阻塞
      - 写写：阻塞

      所以，如果在系统中，读操作次数远远大于写操作，则读写锁就可以发挥最大的功效，提升系统性能

    - 1.4 CopyOnWrite：读写分离锁的读和写还是互斥的，在写的时候还是不能读的，在读多写少的场景下，为了把读的性能发挥到极致，我们希望读操作尽可能快，而写操作即使慢一点也没关系。由于读操作不会修改原有数据，因此对于每次读取都进行加锁其实都是一种资源浪费。根据读写锁的思想，读和读之间是不冲突的，但是读操作会受到写操作的阻碍，当写操作发生时，读就必须等待（反之亦然）。但是在读多写少的场景下，为了将读操作的性能发挥到极致，则希望实现读操作不加锁，同时读和写操作也不用互相等待，只有写和写之间是需要等待的，这样一来，读操作的性能就会大幅度提升。
    
      所以总结来说，CopyOnWriteArraylist的访问约束如下：
      - 读读：非阻塞
      - 读写：非阻塞
      - 写读：非阻塞
      - 写写：阻塞

      具体实现：所谓 CopyOnWrite，就是在写操作的时候，进行一次复制，也即，当这个 List 需要修改时，并不修改原有的内容（保证当前读线程的数据一致性），而是对原有数据进行一次复制，将修改的内容写入复本。写完之后，再将修改完的复本替换原来的数据。其内部用了一个 ReentrantLock 来控制写-写的情况，在写操作的时候，先对整个数组进行完整复制，然后在复制之后的数组基础上进行写，写完之后再替换回去；

      但是在写多读少的场景下不合适，因为写操作会竞争锁，而且会进行整个数组的拷贝操作，比较耗时，所以写的性能比较差；

    - 1.5 锁分离：基于读写分离锁思想的扩展，读写分离锁是根据操作功能的不同进行锁的分离，也可以采取类似的思想来对锁进行分离。比如LinkedBlockingQueue，take和put方法分别实现从队列取得元素和增加元素，虽然都是对链表进行修改，但两个操作分别位于队列的前端和尾端，因此理论上不冲突，可以分离为take锁和put锁；


关键出队入队代码如下：
```java
/**
     * Links node at end of queue.
     *
     * @param node the node
     */
private void enqueue(Node<E> node) {
        // assert putLock.isHeldByCurrentThread();
        // assert last.next == null;
        last = last.next = node;
    }
//增加队列尾部节点的时候，操作的是原尾部节点的next值，同时将last重新指向新增的尾部节点

    /**
     * Removes a node from head of queue.
     *
     * @return the node
     */
    private E dequeue() {
        // assert takeLock.isHeldByCurrentThread();
        // assert head.item == null;
        Node<E> h = head;
        Node<E> first = h.next;
        h.next = h; // help GC
        head = first;
        E x = first.item;
        first.item = null;
        return x;
    }
 //获取队列头部节点的时候， 是将head指向下个元素作为新的队列头部节点，同时返回该元素的item值然后将item值置为null
 ```

 从上面描述可以看出，take和put操作的是不同节点或者即使是同一个节点也是不同的字段（item or next），因此不冲突；
初始的时候head节点 和 last节点 都指向同一个Node（<E>），其中item和next都为null

2) 无锁：对于并发的控制而言，锁是一种悲观的策略，它总是假设每一次的临界区操作都会产生冲突，而无锁是一种乐观的策略，它会假设对共享资源的访问是没有冲突的，但真的遇到了冲突如何处理？无锁的策略采用一种比较交换的技术（CAS Compare And Swap）来鉴别线程冲突，一旦检测到冲突产生，就重试当前操作（spin）直到没有冲突产生。

    CAS（Compare And Swap：比较交换，一种无锁（lock free）的策略）：包含三个参数CAS（V，E、N），V表示要更新的内存变量值，E表示预期值，N表示新值，仅当V的值等于预期值E的时候，才会将N的值更新为N值，如果V值不等于E值，说明期间已经有其他线程做了更新，则当前线程什么也不做，最后CAS返回当前V的真实值。该操作是一个原子操作，在Java中，CAS主要是由sun.misc.Unsafe这个类通过JNI调用CPU底层指令实现。

    JDK并发包里有一个atomic包，里面实现了一些直接使用CAS操作的线程安全的类型，比如AtomicInteger，与Integer不同，他是可变的，而且是线程安全的，对其进行任何修改操作，都是通过CAS指令完成的。

核心代码：
```java
//AtomicInteger类
private volatile int value;
private static final Unsafe unsafe = Unsafe.getUnsafe();
private static final long valueOffset;//保存着value字段在AtomicInteger对象中的偏移量，是实现比较交换的关键，因为底层使用的unSafe类会用到
static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
}

public final int incrementAndGet() {
  for (;;) 
    { 
     int current = get(); 
     int next = current + 1; 
     if (compareAndSet( current, next)) 
     return next; 
  } 
 }

//Unsafe类
public final boolean compareAndSet(int expect,int update){
    return unsafe.compareAndSwapInt(this,valueOffset,expect,update);//使用CAS原子指令来完成
}

//for (;;) 的必要性：因为CAS操作未必是成功的，因此对于不成功的情况，需要不断地进行尝试；
//核心是compareAndSet方法，这个方法调用的是UnSafe类的compareAndSwapInt方法，而这是个native方法，做了一些类似指针的操作，使用的CPU的原子CAS指令来完成的；
```

**ConcurrentSkipListMap：**
基于跳表实现的高并发高性能map，无锁，基于CAS+spin来实现

在硬件层面，大部分的现代处理器已经支持原子化的CAS指令，因此，JDK5.0之后，虚拟机遍可以使用这个指令来实现并发的CAS操作；

**CAS（Compare And Swap）适用场景：**\
资源竞争较少的情况，对于资源竞争严重的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized
比如上面的代码中，如果compareAndSet(current, next)方法成功执行，则直接返回；如果线程竞争激烈，导致compareAndSet(current, next)方法一直不能成功执行，则会一直循环等待，直到耗尽cpu分配给该线程的时间片，从而大幅降低效率。

**CAS的ABA问题：**\
比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。一般情况下，发生这种情况的概率很小，而且即使发生了可能也不是什么问题。但是，还可能存在另外一种场景，就是我们是否能够修改对象的值，不仅取决于当前值，还和对象的过程变化有关。

解决方案：AtomicStampedReference，通过控制变量值的版本（时间戳）来保证CAS的正确性

其内部不仅维护了对象值，还维护了一个时间戳，当其对应的数值被修改时，除了更新数据本身之外，还必须要更新时间戳，当设置对象值时，对象值以及时间戳都必须满足期望值，写入才能成功。

#### **ThreadLocal:**\
线程的私有变量，只有当前线程可以访问，因此是线程安全的

**实现原理**：\
多个线程往同一个ThreadLocal里放值的时候，先取得当前线程（Thread.currentThread()），然后获取当前线程的ThreadLocalMap（类似一个HashMap）对象，然后将ThreadLocal对象作为key，将要放置的值作为value，放入该线程的ThreadLocalMap。

线程退出的时候，会在exit方法中，对ThreadLocalMap进行清理（置为null），以方便释放对象；

#### **InheritableThreadLocal：**\
用于子线程从父线程继承父线程的私有变量值，当一个子线程创建的时候，如果子线程的构造方法中的参数boolean inheritThreadLocals为true（默认）且父线程的inheritableThreadLocals不为null，则子线程对父线程的inheritableThreadLocals做一个浅层拷贝后赋值给自己的inheritableThreadLocals变量，通常子线程继承的值与父线程完全一样，但也可以通过覆盖ThreadLocal的childvalue方法来实现子线程的值

核心代码如下：
```java
//Thread类定义
public class Thread{
    /* ThreadLocal values pertaining to this thread. This map is maintained
     * by the ThreadLocal class. */
    ThreadLocal.ThreadLocalMap threadLocals = null;

    /*
     * InheritableThreadLocal values pertaining to this thread. This map is
     * maintained by the InheritableThreadLocal class.
     */
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;

    //Thread类的构造方法都默认会调用的私有初始化方法
    private void init(ThreadGroup g, Runnable target, String name,
                      long stackSize, AccessControlContext acc,
                      boolean inheritThreadLocals) {
    //获取父线程
    Thread parent = currentThread();
    //如果父线程的inheritableThreadLocals变量不为null，则进行变量拷贝
    if (inheritThreadLocals && parent.inheritableThreadLocals != null)
            this.inheritableThreadLocals =
                ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
    }
}

//ThreadLocal类定义
public class ThreadLocal<T> {
    
    //静态工厂方法，返回一个保存了从父线程继承变量的ThreadLocalMap
    static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {
            return new ThreadLocalMap(parentMap);
    }

    //map的浅拷贝过程
    static class ThreadLocalMap {
         private ThreadLocalMap(ThreadLocalMap parentMap) {
            Entry[] parentTable = parentMap.table;
            int len = parentTable.length;
            setThreshold(len);
            table = new Entry[len];

            for (int j = 0; j < len; j++) {
                Entry e = parentTable[j];
                if (e != null) {
                    @SuppressWarnings("unchecked")
                    ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();
                    if (key != null) {
                        Object value = key.childValue(e.value);//关键部分，可以通过覆盖childvalue方法来改变子线程的初始值
                        Entry c = new Entry(key, value);
                        int h = key.threadLocalHashCode & (len - 1);
                        while (table[h] != null)
                            h = nextIndex(h, len);
                        table[h] = c;
                        size++;
                    }
                }
            }
        }
    }
}

//InheritableThreadLocal类定义
public class InheritableThreadLocal<T> extends ThreadLocal<T> {
    /**
     * Computes the child's initial value for this inheritable thread-local
     * variable as a function of the parent's value at the time the child
     * thread is created.  This method is called from within the parent
     * thread before the child is started.
     * <p>
     * This method merely returns its input argument, and should be overridden
     * if a different behavior is desired.
     *
     * @param parentValue the parent thread's value
     * @return the child thread's initial value
     */
    protected T childValue(T parentValue) {
        return parentValue;
    }

    /**
     * Get the map associated with a ThreadLocal.
     *
     * @param t the current thread
     */
    ThreadLocalMap getMap(Thread t) {
       return t.inheritableThreadLocals;
    }

    /**
     * Create the map associated with a ThreadLocal.
     *
     * @param t the current thread
     * @param firstValue value for the initial entry of the table.
     */
    void createMap(Thread t, T firstValue) {
        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);
    }
}
```

#### **TransmittableThreadLocal：**\
在使用线程池等会缓存线程的组件情况下，提供ThreadLocal值的传递功能，解决异步执行时上下文传递的问题。JDK的InheritableThreadLocal类可以完成父线程到子线程的值传递。但对于使用线程池等会缓存线程的组件的情况，线程由线程池创建好，并且线程是缓存起来反复使用的，这时父子线程关系的ThreadLocal值传递已经没有意义，应用需要的实际上是把任务提交给线程池时的ThreadLocal值传递到任务执行时。

几个典型场景例子：
1. 分布式跟踪系统
2. 应用容器或上层框架跨应用代码给下层SDK传递信息
3. 日志收集记录系统上下文

解决方法分为如下几种：
1. 修饰Runnable和Callable

    使用com.alibaba.ttl.TtlRunnable和com.alibaba.ttl.TtlCallable来修饰传入线程池的Runnable和Callable

    核心处理逻辑是，在创建Runnable的wraper类TtlRunnable的时候，TtlRunnable从TransmittableThreadLocal中拷贝并备份变量值（因为创建TtlRunnable和提交任务的方法是在同一个线程中执行），然后在线程池中的缓存线程开始执行Runnable任务之前，TtlRunnable重新将备份的变量值放入TransmittableThreadLocal中（这个时候是在执行任务的线程中），这样Runnable的run方法被调用的时候，从TransmittableThreadLocal中就可以拿到TtlRunnable放入的值（也即提交任务的线程的私有变量值）。Callable原理类似。

2. 修饰线程池

    省去每次Runnable和Callable传入线程池时的修饰，这个逻辑可以在线程池中完成，通过工具类com.alibaba.ttl.threadpool.TtlExecutors完成

    其核心逻辑是修饰submit方法，在该方法中调用TtlRunnable和TtlCallable来修饰Runnable和Callable，完成从TransmittableThreadLocal中拷贝并备份变量值的逻辑。

    ExecutorService executorService = ...
    // 额外的处理，生成修饰了的对象executorService
    executorService = TtlExecutors.getTtlExecutorService(executorService);

3. 使用Java Agent来修饰JDK线程池实现类

    这种方式，实现线程池的传递是透明的，代码中没有修饰Runnable或是线程池的代码，即可以做到应用代码『无侵入』

    Agent中，修饰了jdk中的两个线程池实现类（实现代码在TtlTransformer.java）：java.util.concurrent.ThreadPoolExecutor、java.util.concurrent.ScheduledThreadPoolExecutor

    在Java的启动参数加上：-Xbootclasspath/a:/path/to/transmittable-thread-local-2.x.x.jar -javaagent:/path/to/transmittable-thread-local-2.x.x.jar

    Agent修改是JDK的类，类中加入了引用TTL的代码，所以TTL Agent的Jar要加到bootclasspath上

#### **JavaAgent实现机制**
1. 主要的功能如下
    - a)可以在加载java文件之前做拦截把字节码做修改
    - b)可以在运行期将已经加载的类的字节码做变更，但是这种情况下会有很多的限制
    - c)还有其他的一些小众的功能
       - 获取所有已经被加载过的类
       - 获取所有已经被初始化过了的类（执行过了clinit方法，是上面的一个子集）
       - 获取某个对象的大小
       - 将某个jar加入到bootstrapclasspath里作为高优先级被bootstrapClassloader加载
       - 将某个jar加入到classpath里供AppClassloard去加载
       - 设置某些native方法的前缀，主要在查找native方法的时候做规则匹配

javaagent的运行依赖于一个特殊的JVMTIAgent：Instument Agent

**JVMTI（JVM Tool Interface）是什么？**\
JVMTI 提供了一套”代理”程序机制，可以支持第三方工具程序以代理的方式连接和访问 JVM，并利用 JVMTI 提供的丰富的编程接口，完成很多跟 JVM 相关的功能

JVM Tool Interface，是jvm暴露出来的一些供用户扩展的接口集合，JVMTI是基于事件驱动的，JVM每执行到一定的逻辑就会调用一些事件的回调接口（如果有的话），这些接口可以供开发者去扩展自己的逻辑。比如说我们最常见的想在某个类的字节码文件读取之后类定义之前能修改相关的字节码，从而使创建的class对象是我们修改之后的字节码内容，那我们就可以实现一个回调函数赋给JVMTIEnv（JVMTI的运行时，通常一个JVMTIAgent对应一个JVMTIEnv，但是也可以对应多个）的回调方法集合里的ClassFileLoadHook，这样在接下来的类文件加载过程中都会调用到这个函数里来。

**JVMTIAgent是什么？**\
JVMTIAgent其实就是一个动态库，利用JVMTI暴露出来的一些接口来干一些我们想做但是正常情况下又做不到的事情，不过为了和普通的动态库进行区分，它一般会实现如下的一个或者多个函数
- Agent_OnLoad函数：如果agent是在启动的时候加载的，也就是在vm参数里通过-agentlib来指定，那在启动过程中就会去执行这个agent里的Agent_OnLoad函数。
- Agent_OnAttach函数：如果agent不是在启动的时候加载的，是我们先attach到目标进程上，然后给对应的目标进程发送load命令来加载agent，在加载过程中就会调用Agent_OnAttach函数。
- Agent_OnUnload函数：在agent做卸载的时候调用，不过貌似基本上很少实现它
比如eclipse对java代码做调试的jwdp agent就是一个JVMTIAgent

**Instrument以及Instrument Agent是什么？**\
Instrumentation 的最大作用，就是类定义动态改变和操作，“java.lang.instrument”包的具体实现，依赖于 JVMTI，在 Instrumentation 的实现当中，存在一个 JVMTI 的代理程序，通过调用 JVMTI 当中 Java 类相关的函数来完成 Java 类的动态操作

Instrument Agent则是一个JVMTIAgent（linux下对应的动态库是libinstrument.so），还有个别名叫JPLISAgent(Java Programming Language Instrumentation Services Agent)，就是专门为java语言编写的插桩服务提供支持的，因此javaagent的功能就是基于这个来实现的。

其实现了Agent_OnLoad和Agent_OnAttach两方法，也就是说我们在用它的时候既支持启动的时候来加载agent，也支持在运行期来动态来加载这个agent，运行期动态加载agent依赖的是jvm的attach机制，通过发送load命令来加载agent。不管是启动时还是运行时加载的instrument agent都关注着同一个jvmti事件---ClassFileLoadHook，这个事件是在读取字节码文件之后回调时用的，这样可以对原来的字节码做修改。

**Class Transform的实现**\
主要是针对第一次类文件加载的时候就要求被transform的场景，在加载类文件的时候发出ClassFileLoad的事件，然后交给instrumenat agent来调用javaagent里注册的ClassFileTransformer实现字节码的修改