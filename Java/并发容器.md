**并发容器**
- **ConcurrentHashMap**：线程安全且在多线程环境下高性能的HashMap
如果仅仅需要一个线程安全的HashMap，一种可行的方法是使用 Collections.synchroniezdMao()方法来包装 HashMap，通过使用代理方式，将所有 Map 相关的功能都交给包装的 HashMap 来实现，而自己主要负责保证线程安全.这个包装的 Map 可以满足线程安全的要求，但是在多线程环境下性能不算好。

ConcurrentHashMap是通过减小锁粒度的方法来实现多线程环境下的高性能，所谓减小锁粒度，是指缩小锁定对象的范围，从而减少锁冲突的可能性，进而提高系统并发能力。
具体实现：

ConcurrentHashMap内部进一步细分了若干个小的HashMap，称之为段（segment），默认情况下，一个ConcurrentHashMap被进一步细分成16个段。这样的话，如果需要在ConcurrentHashMap中增加一个新的 entry，并不是将整个 HashMap 加锁，而是首先根据 hashcode 得到该 entry 会被存放到哪个段中，然后对该段加锁，并完成put 操作。在多线程环境下，只要被put 的 entry 不存放到同一个段中，则线程间就可以做到真正的并行。

注意一下，ConcurrentHashMap在JDK1.7和JDK1.8中的实现是不一样的：
1) JDK1.7：
  - 每一个Segment都继承了ReentrantLock，且包含一个HashEntry<K,V>[] table， table中的每一个元素本质上都是一个HashEntry的单向链表；
  - 构造ConcurrentHashMap如果不传入任何参数，则模式初始容量是16，负载因子是0.75，并发等级是16（潜台词segment 数和初始bucket数是一样的，每个 bucket 一个锁）

2) JDK1.8
  - 没有使用segment，直接使用Node<K,V>[] table保存数据，采用table数组元素（链表头节点）作为锁（用synchronized获取数组元素的锁对象），进一步减少并发冲突的概率;
  - 将原先table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构，对于个数超过8(默认值)的链表，转换成红黑树的结构，那么查询的时间复杂度可以降低到O(logN)，可以改进性能；

ConcurrentHashMap减小锁粒度引入的问题：
当一些操作（比如 size 方法）需要取得全局锁时，就会需要取得所有段的锁才能执行，消耗的资源会比较多，性能也会比较差。因此，只有在类似 size （）获取全局信息的方法调用不频繁的时候，这种减小锁粒度的方法才能真正意义上提高系统吞吐量；

- **ConcurrentSkipListMap**：基于跳表实现的高并发高性能map，无锁，基于CAS+spin来实现
跳表是一种用来快速查找的数据结构（类似平衡树）
vs 平衡树的区别：对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整，而对跳表的插入和删除只需要对整个数据结构的局部进行操作即可，这样带来的好处是，在高并发的情况下，红黑树需要一个全局锁来保证整个平衡树的线程安全，而跳表只需要部分锁即可，这样在高并发的环境下，跳表可以拥有更好的性能。

跳表的数据结构实现特点：
1.同时维护了多个链表，并且链表是分层的，最低层的链表维护了跳表内所有的元素，每上面一层链表都是下面一层的子集。换句话说，如果一个元素出现在Level i 的链表中，则它在 Level i 之下的链表也都会出现，上层的多层链表类似建立了多级索引；
2.跳表内的所有链表的元素都是有序的；
3.每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素；

跳表是一种空间换时间的算法，插入、删除、查找的复杂度均为O(logN)。注：redis的sorted set数据结构是基于跳表实现的
1.搜索（查找）：从顶层链表开始查找，一旦发现被查找的元素大于当前链表中的取值，则转入下一层链表继续查找，也即查找过程中，是跳跃式的；
2.插入：先确定该元素要插入的层数K（采用完全随机的算法）,  然后在level K，level k-1一直到level 1各层的链表都插入该元素，如果 K 大于链表的层数，则要添加新的层；
3.删除：在各个层中找到包含 x 的节点，使用标准的链表删除节点的方法删除该节点；

ConcurrentSkipListMap VS ConcurrentHashMap
哈希map不会保存元素的顺序，而跳表内所有的元素都是有序的，因此在对跳表进行遍历的时候，可以得到一个有序的结果
元素的顺序比较通过自然顺序（元素实现comparable接口）和自定义comparator来实现

（3）CopyOnWriteArrayList（适用于读多写少的场景）：很多应用场景中，读操作可能会远远大于写操作，在这种场景下，我们希望读操作尽可能快，而写操作即使慢一点也没关系。由于读操作不会修改原有数据，因此对于每次读取都进行加锁其实都是一种资源浪费。根据读写锁的思想，读和读之间是不冲突的，但是读操作会受到写操作的阻碍，当写操作发生时，读就必须等待（反之亦然）。但是在读多写少的场景下，为了将读操作的性能发挥到极致，则希望实现读操作不加锁，同时读和写操作也不用互相等待，只有写和写之间是需要等待的，这样一来，读操作的性能就会大幅度提升。
所以总结来说，CopyOnWriteArraylist的访问约束如下：
读读：非阻塞
读写：非阻塞
写读：非阻塞
写写：阻塞

具体实现：所谓 CopyOnWrite，就是在写操作的时候，进行一次复制，也即，当这个 List 需要修改时，并不修改原有的内容（保证当前读线程的数据一致性），而是对原有数据进行一次复制，将修改的内容写入复本。写完之后，再将修改完的复本替换原来的数据。**其内部用了一个 ReentrantLock 来控制写-写的情况**，在写操作的时候，先对整个数组进行完整复制，然后在复制之后的数组基础上进行写，写完之后再替换回去；
但是在写多读少的场景下不合适，因为写操作会竞争锁，而且会进行整个数组的拷贝操作，比较耗时，所以写的性能比较差；

（4）BlockingQueue（阻塞队列）
使用阻塞算法的队列可以用一个锁（入队和出队用同一把锁，如ArrayBlockingQueue）或两个锁（入队和出队用不同的锁，如LinkedBlockingQueue）等方式来实现
BlockingQueue是接口，具体实现有 ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue 等
ArrayBlockingQueue 是基于数组实现的，LinkedBlockingQueue是基于链表，PriorityBlockingQueue则是基于heap
ArrayBlockingQueue更适合做有界队列，因为队列中可容纳的最大元素需要在队列创建时指定
LinkedBlockingQueue适合做无界队列或者边界值非常大的队列，因为其内部元素可以动态增加
PriorityBlockingQueue也适合做无界队列

4.1 ArrayBlockingQueue的实现（入队和出队用同一把锁，入队操作和出队操作互相会阻塞）：
1.必须指定capacity，capacity即数组的length，因此是一个有界队列，用count标识数组中实际元素个数，初始为0；
2.通过putIndex和takeIndex来指定下一次put和take操作（同理offer和poll）的item位置，初始都是0，在达到数组的length后，都会重置为0再重新开始；
3.通过 ReentrantLock 和 notEmpty 、notFull 两个 Condition 来实现队列满或空的时候的阻塞控制，notEmpty阻塞的条件是count == 0（即元素个数为0），notFull阻塞的条件是count==length（即元素个数等于数组长度）；
4.通过 Put 和 take 两个操作来实现元素入队列和出队列的过程，为实现队列 FIFO 的效果，put 操作从数组 index==0的位置一直 put 到index==length -1，然后再从 index==0开始，take 操作也一样；

```Java
public void put(E e) throws InterruptedException {
        checkNotNull(e);
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == items.length)
                notFull.await();
            enqueue(e);
        } finally {
            lock.unlock();
        }
}

private void enqueue(E x) {
        // assert lock.getHoldCount() == 1;
        // assert items[putIndex] == null;
        final Object[] items = this.items;
        items[putIndex] = x;
        if (++putIndex == items.length)
            putIndex = 0;
        count++;
        notEmpty.signal();
}

public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == 0)
                notEmpty.await();
            return dequeue();
        } finally {
            lock.unlock();
        }
}

private E dequeue() {
        // assert lock.getHoldCount() == 1;
        // assert items[takeIndex] != null;
        final Object[] items = this.items;
        @SuppressWarnings("unchecked")
        E x = (E) items[takeIndex];
        items[takeIndex] = null;
        if (++takeIndex == items.length)
            takeIndex = 0;
        count--;
        if (itrs != null)
            itrs.elementDequeued();
        notFull.signal();
        return x;
}
```

offer()&poll（）操作与put()&take()操作的区别：
offer()&poll（）在队列Full或empty的时候，不会阻塞等待notFull或notEmpty，直接返回false，否则才会尝试获取Lock进行enqueue或dequeue操作


4.2 LinkedBlockingQueue的实现（入队和出队用不同的锁，入队操作和出队操作互相不阻塞）：
1.不指定capacity的时候，默认容量是Integer.Max_Value，因此可以作为一个无界队列或者很大容量的有界队列；
2.初始状态下head和tail指向一个value==null&next==null的node，初始count==0标识队列的元素个数；
3.put操作时会先尝试获取putLock，获取锁成功后会先判断count是否==capacity，如果是则等待notFull的condition，如果不是则进行enqueue操作插入node，完成会增加count（AtomicInteger.getAndIncrement）;
4.take操作时会先尝试获取takeLock，获取锁成功后会先判断count是否==0，如果是则等待notEmpty的condition，如果不是则进行dequeue操作删除node，完成会减少count（AtomicInteger.getAndDecrement）；

因为 take 和 put 操作分别实现从队列取得数据和增加数据的功能，但由于是链表结构，所以，两个操作一个作用于队列头部，一个作用于队列尾部，理论上并不冲突（即使同时操作一个Node节点，put操作主要操作的是node的next值，take操作操作的是node的item值，也不冲突）。因此，一把 takeLock，take操作的时候持有，一把 putLock，put 操作的时候持有，take 和 put 持有的是不同的锁（锁分离），takeLock 创建 conditon 判断是否 notEmpty，putLock 创建 condition 判断是否 notFull

```java
private void enqueue(Node<E> node) {
        // assert putLock.isHeldByCurrentThread();
        // assert last.next == null;
        last = last.next = node;
}

private E dequeue() {
        // assert takeLock.isHeldByCurrentThread();
        // assert head.item == null;
        Node<E> h = head;
        Node<E> first = h.next;
        h.next = h; // help GC 自引用
        head = first;
        E x = first.item;
        first.item = null;
        return x;
    }
```

offer()&poll（）操作与put()&take()操作的区别：
offer()&poll（）在队列Full或empty的时候，不会阻塞等待notFull或notEmpty，直接返回false，否则才会尝试获取putLock或takeLock进行enqueue或dequeue操作

4.3 SynchronousQueue（阻塞队列，无容量队列）
不像ArrayBlockingQueue或LinkedListBlockingQueue，SynchronousQueue内部并没有数据缓存空间，你不能调用peek()方法来看队列中是否有数据元素，因为数据元素只有当你试着取走的时候才可能存在，不取走而只想偷窥一下是不行的，当然遍历这个队列的操作也是不允许的。队列头元素是第一个排队要插入数据的线程，而不是要交换的数据。数据是在配对的生产者和消费者线程之间直接传递的，并不会将数据缓冲数据到队列中。可以这样来理解：生产者和消费者互相等待对方，握手，然后一起离开。
JDK5实现：基于ReentrantLock+queue来实现
JDK6实现：使用了性能更好的无锁算法— 扩展的“Dual stack and Dual queue”算法，竞争机制支持公平和非公平两种：非公平竞争模式使用的数据结构是后进先出栈(Lifo Stack)；公平竞争模式则使用先进先出队列（Fifo Queue）

（5）ConcurrentLinkedQueue（无界非阻塞的线程安全高性能并发队列,非阻塞基于CAS+spin实现）：
基于CAS操作，而不依赖锁，大幅提升并发性能
核心代码：
```java
 private static class Node<E> {
        volatile E item;
        volatile Node<E> next;

        /**
         * Constructs a new node.  Uses relaxed write because item can
         * only be seen after publication via casNext.
         */
        Node(E item) {
            UNSAFE.putObject(this, itemOffset, item);
        }

        boolean casItem(E cmp, E val) {
            return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val);
        }

        void lazySetNext(Node<E> val) {
            UNSAFE.putOrderedObject(this, nextOffset, val);
        }

        boolean casNext(Node<E> cmp, Node<E> val) {
            return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);
        }

        // Unsafe mechanics

        private static final sun.misc.Unsafe UNSAFE;
        private static final long itemOffset;
        private static final long nextOffset;

        static {
            try {
                UNSAFE = sun.misc.Unsafe.getUnsafe();
                Class<?> k = Node.class;
                itemOffset = UNSAFE.objectFieldOffset
                    (k.getDeclaredField("item"));
                nextOffset = UNSAFE.objectFieldOffset
                    (k.getDeclaredField("next"));
            } catch (Exception e) {
                throw new Error(e);
            }
        }
    }

     /**
     * Inserts the specified element at the tail of this queue.
     * As the queue is unbounded, this method will never return {@code false}.
     *
     * @return {@code true} (as specified by {@link Queue#offer})
     * @throws NullPointerException if the specified element is null
     */
    public boolean offer(E e) {
        checkNotNull(e);
        final Node<E> newNode = new Node<E>(e);

        for (Node<E> t = tail, p = t;;) {
            Node<E> q = p.next;
            if (q == null) {
                // p is last node
                if (p.casNext(null, newNode)) {
                    // Successful CAS is the linearization point
                    // for e to become an element of this queue,
                    // and for newNode to become "live".
                    if (p != t) // hop two nodes at a time
                        casTail(t, newNode);  // Failure is OK.
                    return true;
                }
                // Lost CAS race to another thread; re-read next
            }
            else if (p == q)
                // We have fallen off list.  If tail is unchanged, it
                // will also be off-list, in which case we need to
                // jump to head, from which all live nodes are always
                // reachable.  Else the new tail is a better bet.
                p = (t != (t = tail)) ? t : head;
            else
                // Check for tail updates after two hops.
                p = (p != t && t != (t = tail)) ? t : q;
        }
    }

    public E poll() {
        restartFromHead:
        for (;;) {
            for (Node<E> h = head, p = h, q;;) {
                E item = p.item;

                if (item != null && p.casItem(item, null)) {
                    // Successful CAS is the linearization point
                    // for item to be removed from this queue.
                    if (p != h) // hop two nodes at a time
                        updateHead(h, ((q = p.next) != null) ? q : p);
                    return item;
                }
                else if ((q = p.next) == null) {
                    updateHead(h, p);
                    return null;
                }
                else if (p == q)
                    continue restartFromHead;
                else
                    p = q;
            }
        }
    }
```

数据结构
（1）Java Collection框架：
collection-》set、list
map-》hashmap、treemap

hashset vs treeset
分别基于 hashmap 和 treemap 来实现的

arraylist vs linkedlist

arraylist vs vector 的区别：vector 是synchronized

linkedlist：双向链表实现
Operations that index into the list will traverse the list from the beginning or the end, whichever is closer to the specified index.

Map：<<——implents   <——extends
java.util.Map<<——AbstractMap<——HashMap<——LinkedHashMap
java.util.Map<<——SortedMap<——NavigableMap<——TreeMap
java.util.Map<<——HashTable
Dictonary<——HashTable

(1) HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。

(2) Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。

(3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。

(4) TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。

对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。

Hashmap
几个关键字段：
int threshold;             // 所能容纳的key-value对极限 
final float loadFactor;    // 负载因子
int modCount;  //记录结构修改次数，遍历的时候根据这个判断是否抛出ConcurrentModifyException
int size;
1.Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。结合负载因子的定义公式可知，threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。
2.size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别;
3.modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化；

Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算
方法一：
```java
static final int hash(Object key) {   //jdk1.8 & jdk1.7
     int h;
     // h = key.hashCode() 为第一步 取hashCode值
     // h ^ (h >>> 16)  为第二步 高位参与运算
     return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
方法二：
static int indexFor(int h, int length) {  //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的
     return h & (length-1);  //第三步 取模运算
}
```

方法二非常巧妙，它通过h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率；
在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销
HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)

总结：
(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。

(2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。

(3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。

(4) JDK1.8引入红黑树大程度优化了HashMap的性能。

TreeMap：基于红黑树实现，实现了 comparable接口，元素通过该接口的 compareto方法实现排序，或者通过设置一个  Comparator 来实现自定义顺序
strongly recommended(though not required)：if e1.compareTo(e2) == 0 has the same boolean value as e1.equals(e2) for every e1 and e2 of class C