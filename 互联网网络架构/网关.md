# **API网关**

网关（Gateway）这个词在计算机科学中，尤其是在计算机网络中很常见，用于表示**位于内部区域边缘**，与外界进行交互的某个物理或逻辑设备

一句话概括：Exposes your services as managed APIs（将内部的服务以可控可管的方式暴露出去，关键词是暴露和管控）,管理**南北流量**，解决**横切关注点（cross-cutting concerns）**

API网关是系统的唯一入口，从面向对象设计的角度看，它与Facade外观模式类似。API网关封装了系统内部架构，为每个客户端提供一个定制的API。它可能还具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。

API网关方式的核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，**在网关层处理所有的非业务功能**。通常，网关也是提供REST/HTTP的访问API。服务端通过API-GW注册和管理服务

负载均衡器与服务网关的区别在于，前者是为了根据均衡算法对流量进行平均地路由，后者是为了根据流量中的某种特征进行正确地路由。

也就是说，网关必须能够识别流量中的特征，这意味着网关能够支持的网络层次、通讯协议的数量，将会直接限制后端服务节点能够选择的服务通讯方式：
1.如果服务集群只提供如 Etcd 这类直接基于 TCP 访问的服务，那就可以只部署四层网关，以 TCP 报文中的源地址、目标地址为特征进行路由；
2.如果服务集群要提供 HTTP 服务的话，就必须部署一个七层网关，根据 HTTP 的 URL、Header 等信息为特征进行路由；
3.如果服务集群要提供更上层的 WebSocket、SOAP 等服务，那就必须要求网关同样能够支持这些上层协议，才能从中提取到特征；

Chris Richardson 在他的博客中把 API 网关划分为以下两种：
1.单节点API网关
2.BFF（Backends for frontends）网关

### **单节点网关**

![single-gateway](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/single-gateway.png)

单节点API网关为每个客户端提供不同的API，而不是提供一种万能风格的API

2.BFF（Backend For FrontEnd）网关
![bff-gateway](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/BFF-gateway.png)

这种模式是针对不同的客户端来实现一个不同的API网关

BFF（Backend For Frontend）

背景：服务端需要支持多种前端设备下的用户体验时，常常面临现有API与某一端UI紧耦合的情况

因此，我们不再寄希望于一个大后端为多端体验统一提供API支持，而是给每种用户体验对应一个后端（one backend per user experience），称为Backend For Frontend (BFF)，译作用户体验适配层
Consequently it’s often best to define different back-end services for each kind of front-end client.
概念上，把每个前端应用拆成两部分：客户端应用与服务端的部分（BFF）。其中，BFF是面向特定用户体验的，由实现这部分UI的前端团队负责实现及维护（即UI与对应的BFF由同一个团队负责）
These back ends should be developed by teams aligned with each front end to ensure that each back end properly meets the needs of its client.

BFF主要干的事情：

1) 聚合：合并多个接口调用；
2) 适配: 常见的是格式化，格式化成某个端想要的数据格式；
3) 裁剪：去掉某个端不需要的信息；

BFF模式最大好处是关注点分离（separation of concerns），下游服务可以专注于业务领域模型，前端UI专注于用户体验：
后端可以专注于业务领域，更多从领域模型的视角去思考问题，页面渲染视角的数据则交给前端型全栈工程师去搞定。领域模型与页面数据是两种思维模式，通过BFF可以很好地解耦开，让彼此更专业高效。

### **GraphQL+Springboot实现BFF**

Facebook 要解决的问题是广泛连接的数据对象之间的复杂查询，也就是 graph 上面有非常多互联互通的 nodes，而且这些 node 的类型多，甚至是它们之间 edge 的类型也如此。GraphQL 顾名思义就是用来 query graph 的，但你首先需要有一个 graph。如果没有 graph，就如同没有结构化数据却尝试用 SQL 一样，无法解决核心问题。这一点就限制了 GraphQL 受众大小。

GraphQL 开源了协议，但实际的 implementation 没有开源，使用门槛并不低。虽然谁都可以根据协议做一个实现，但 Facebook 内部实现并没有公开，最终能否被广泛使用要看是否有人能做出来足够好的开源实现。类似的事情在历史上发生过很多次：Facebook 公开过 BigPipe 的概念但没有被广泛使用；

Google 公开的 BigTable 概念也没有被广泛采用，但由此而来的 Hadoop 被广泛使用。所以现在的问题是 GraphQL 的 Hadoop 会不会出现。

#### **GraphQL的几个定义**

GraphQL 是一个开源的查询语言和协议 API，它与 REST 都是用来构建和使用 API 的规范。

GraphQL是一种针对graph（图状数据）进行操作的语言，它是面向前端的，让前端可以拥有”自定义查询数据“的能力。图状数据意味着GraphQL想要做一些数据的关联查询而并不是单一维度的数据查询。

GraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的运行时。 GraphQL 对你的 API 中的数据提供了一套易于理解的完整描述，使得客户端能够准确地获得它需要的数据，而且没有任何冗余，也让 API 更容易地随着时间推移而演进，还能用于构建强大的开发者工具

#### **GraphQL  vs  Rest**

#### **REST**

REST是最通用，也是最常用的接口设计方案，它是无状态的，以资源为核心，针对如何操作资源定义了一系列 URL 约定，而操作类型通过 GET POST PUT DELETE 等 HTTP Methods 表示。

存在的问题：

1) 获取多余数据问题
客户端下载的信息量超过了应用程序中实际需要的信息量。例如一个页面，只需要显示一个用户名列表。在REST API 中，此应用程序通常会命中/users接收带有用户数据的 JSON 数组，为了通用性，该接口可能返回更多的用户信息，如生日或者地址。
2) 信息缺失问题
信息缺失通常意味着特定接口不能提供足够的所需信息。客户端需要提出额外的接口来获取所需要的信息

#### **GraphQL**

GraphQL 不是 REST 的替代品，而是另一种交互形式：前端决定后端的返回结果
GraphQL两个核心能力：

1) 获取多个资源只用一个请求
GraphQL查询不仅能够获取资源的属性，而且还能够沿着资源间的引用进一步查询。典型的Rest API请求多个资源的时候需要载入多个URL，而GraphQL可以通过一次请求就后去需要的所有数据，这样一来，即使在比较慢的移动网络连接下，使用GraphQL的应用也能表现的足够迅速。
2) 请求你所要的数据，不多不少
GraphQL可以指定返回你需要的字段，其余的字段不会返回，没有冗余字段
这两个能力正是前端梦寐以求的能力，没有这两个能力的时候，前端得依赖后端的接口支持，增加了沟通成本。因此，GraphQL一定程度上，改变了前后端的协作模式

对于如何改进前后端协作的问题，有两种常见的协作改进方案：

1) 前端主导
前端搭建一个中间层的node.js服务，对已有的服务端接口进行梳理，整个改造过程对服务端透明
2) 服务端主导
服务端搭建一个springBoot服务，对已有的服务端接口进行梳理，前端根据暴露的新服务进行改造

如果用方案2服务端主导，导致的问题是，GraphQL 的利好主要是在于前端的开发效率，但落地却需要服务端的全力配合。如果是小公司或者整个公司都是全栈，那可能可以做，但在很多前后端分工比较明确的团队里，要推动 GraphQL 还是会遇到各种协作上的阻力

但是，从服务端视角来看，方案1可能并不能完美解决性能问题，因为服务端的级联查询可能会导致性能很差，因为，虽然网络层面的请求数被优化了，但数据库查询可能会成为性能瓶颈

![graphql-batch](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/graphql-batch.png)

比如我要查询5个同学和这5个同学语数外的考试成绩，如果服务端只提供了获取单个学生单个学科成绩的接口，那么每个同学需要查询3次数据库，一共需要请求15次数据库，再加上获取学生列表的1次请求，一共是16次。表面上看，GraphQL只需要一次请求就能够完成上面的需求，但是背后却发生了16次调用，显然得不偿失，这就是著名的n+1问题。因此决定性能的核心还是在服务端，如果服务端提供一个批量查询的接口就可以解决问题了。可见GraphQL的性能还是得建立在服务端良好的接口设计的基础之上的。

虽然从服务端视角挑战了GraphQL的能力，但这并不影响前端视角下GraphQL的意义，多个服务聚合成一个服务有些时候是刚需，比如需要在一个页面访问N个服务接口，这个页面需要在H5、android、ios、小程序等各自实现一遍，这个页面的沟通联调成本如下：

![graphql-多端沟通成本](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/graphql-%E5%A4%9A%E7%AB%AF%E6%B2%9F%E9%80%9A%E6%88%90%E6%9C%AC.png)

从项目周期和人力投入成本来看非常庞大，很难接受。但使用GraphQL的服务聚合能力能很好地降低成本。
SpringBoot集成GraphQL
核心步骤如下：

```
1. .graphqls配置文件，如下所示：
type Query {
    user(name: String!): User
    users: [User]
}
type Mutation {
    addUser(name: String!, password: String!): Result
}
type Result {
    respCode: Int!
    msg: String
}
type User {
    id: String!
    name: String!
    password: String!
}
2.对应的，我们要创建java的Result和User对象，如下：
@Data
class User {
    private String id;
    private String name;
    private String password;
}

@Data
class Result {
    private Integer respCode;
    private String msg;
}
3.实现 .graphqls文件中的query类中的方法，需要实现GraphQLQueryResolver，实现 .graphqls文件中的Mutation类中的方法，需要实现GraphQLMutationResolver，实现代码如下：
@Component
public class QueryResolver implements GraphQLQueryResolver 
{ 
    @Resource
    private UserService userService;

    public User user(String name) { 
        return userService.getUser(name);
    }

    public List<User> users() { 
        return userService.listUsers();
    }
}
@Component
public class MutationResolver implements GraphQLMutationResolver 
{ 
    @Resource
    private UserService userService;

    public Result addUser(String name, String password) 
   {
        return userService.addUser(name, password);
    }
}
```

可以看到，我们的方法名称和参数，需要和配置文件中保持一致
 4.最后，可以通过<http://localhost:8080/graphql来访问graphql自带的调试工具，比如我们要查询上面的Users>方法，如下

 ```
query test{
    users {
      id
      name
    }
}
返回如下：
{"data":
{"users":[
{
"id":1,"name":"yafeng"  
},
{
"id":2,"name":"yafeng2" 
},
{
"id":3,"name":"yafeng3" 
}]
}
}
对Mutation类型中的addUser方法，我们可以这样调用：

mutation test{
    addUser(name: "yafeng4", password: "123") 
    {
      respCode
    }
}
返回如下：
{"data":
 {"addUser":{
  "respCode":200
  }
 }
}
```

#### **GrahpQL相比Rest的优势**

1) 通过单一的 API 调用获取信息
如果使用 REST API，那么开发者需要把多个接入点合并起来才能收集到所有需要的数据，因为 REST 散落分布在多个独立的接入点上。GraphQL 与 REST 的主要区别就在这里。开发者仅仅通过一个 API 调用就可以请求到所需信息，而 GraphQL 会专注于主体任务
2) 不会存在过多或者过少获取数据的问题
从 REST 收到的响应来看，有一个不稳定的因素，即收到的信息里要么信息不足，要么信息冗余，这样就不可避免地需要再发出一次请求。而 GraphQL 就解决了这个问题，因为它只需请求一次，就能够获取所需的精确的数据信息
3） 根据你的需求自定义请求格式
开发者按照 REST API 文档描述发出请求时，只能请求一些特定的接入点、相关函数和参数等。而另一方面，GraphQL 可以描述数据类型、字段以及它们之间的任何交互连接点。这就允许 GraphQL 开发者自定义请求格式来获取必要的信息

### **Zuul（英文中怪兽的意思，寓意看门神兽）**

Netfix 开源的 API 网关 Zuul，在 1.0 版本的时候使用的是同步阻塞 I/O 模型，整体系统其实就是一个 servlet，在接收到用户的请求，然后执行在网关中配置的认证、协议转换等逻辑之后，调用后端的服务获取数据返回给用户。

![zuul1-arch](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul1-arch.png)

请求处理生命周期

![zuul1-req-handle](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul1-req-handle.png)

可以通过自定义实现pre routing、routing和post routing等filter，来实现限流、路由、日志等逻辑，可动态发布的过滤器机制是其亮点
Zuul 采用责任链模式，Zuul1 中将 filter 定义为三类：pre routing filter（路由前过滤器）、routing filter（路由过滤器）和 after routing filter（路由后过滤器）。每一个 filter 定义了执行的顺序，在 filter 注册时，会按照顺序插入到 filter chain（过滤器链）中。这样 Zuul 在接收到请求时，就会按照顺序依次执行插入到 filter chain 中的 filter 了

![zuul1-filter](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul1-filter.png)

![zuul1-filter2](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul2-filter2.png)

![zuul1-block-io](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul1-block-io.png)

![zuul1-block-io-problem](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul1-block-io-problem.png)

而在 Zuul2.0 中，Netfix 团队将 servlet 改造成了一个 netty server（netty 服务），采用 I/O 多路复用的模型处理接入的 I/O 请求，并且将之前同步阻塞调用后端服务的方式，改造成使用 netty client（netty 客户端）非阻塞调用的方式。改造之后，Netfix 团队经过测试发现性能提升了 20% 左右

![zuul2-arch](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul2-arch.png)

![zuul2-aio](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul2-aio.png)

![zuul2-aio-problem](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul2-aio-problem.png)

![zuul1-vs-zuul2](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/zuul1-vs-zuul2.png)

网关Gateway主要负责一些跨横切面的逻辑（路由，安全，限流等），也可能包含LB逻辑，比如一种流行做法是网关（Zuul）+客户端软负载（Ribbon）+服务注册中心（Eureka）实现对后端微服务的负载均衡调用

### **Kong**

Kong 是一款基于 OpenResty（Nginx + Lua 模块）编写的高可用、易扩展的网关应用，由 Mashape 公司开源的 API Gateway 项目。Kong 是基于 Nginx 和 Apache Cassandra 或 PostgreSQL 构建的，能提供易于使用的 RESTful API 来操作和配置 API 管理系统

**Kong 的优势：**

1) 可扩展：数据存储在PostgreSQL数据库中，连接相同数据库的节点为同一集群，方便集群的水平扩展。
2) 模块化：可以通过插件功能来扩展Kong的功能，官方提供了一些免费的开源插件，而且自定义开发相对来说简单，插件可通过Restful接口进行配置，非常灵活。
3) 可视化：Kong所有规则对象都提供Restful的接口，这就意味着可以实现配置的可视化管理，开源的工具:Konga

一个完整的Kong服务由四部分实体组成：Target、Upstream、Service和Route

* Target：代表一个物理的应用实例；
* Upstream：是对上游应用的抽象，关联了一组Target实例；
* Service：是服务的抽象，指向一个Upstream来做负载均衡；
* Route：是路由的抽象，负责将实际的Request映射到Service；

![kong-component](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/kong-component.png)

#### **Kong的基本概念**

![kong-basic-concept](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/kong-basic-concept.png)

#### **名词解释：**

* Rout:e 路由通过host, path, header等维度匹配客户端url, 如设置规则 host:www.haodf.com path:/test1 匹配 url: <http://www.haodf.com/test1>

* Service：服务是对后端服务的抽象；
* Upstream：负载均衡对象，用于设置主动或者被动心跳检测机制,负载均衡规则（轮询或者hash）等；
* Target：配置的是后端服务的实际ip和端口；
* Plugins插件：附加功能支持身份验证,限流,拦截等，可作用层级Route,Service,全局。

#### **请求流程简要说明：**

当客户端发起请求时流量会先统一打到 Kong，Kong 通过 Route(路由)对象来匹配规则，再通过 Route 去找当前请求对应的 Service 服务，最后通过 Upstream 负载均衡至后端机器。附加功能（身份验证，黑白名单等）通过 Plugins 插件的形式，附加到 Route 或者 Service 上动态加载，作用于 nginx 请求的各个阶段

#### **Kong插件加载**

Kong 的限流、身份验证等功能都是通过插件来实现的，我们来了解一下 Kong 插件的加载机制

![kong-plugin-load](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/kong-plugin-load.png)

Kong 是 nginx+lua+openresty 的一个实现，上图描述的是 openresty 运行的各个阶段。

* init_by_lua 用于加载 nginx master 进程配置
* init_worker_by_lua 用于加载 nginx worker 进程的配置
* rewrite_by_lua 是用于重写 url 和使用缓存的阶
* access_by_lua 用于权限控制，限流等功能
* header_filter_by_lua 用于对 response header 头进行处理
* body_filter_by_lua 用于对 respone body 体进行重写
* log_by_lua 用于请求的日志记录。

Kong 就是在 openresty 各个阶段加入了 Kong 的 lua 代码来实现一些 Kong 的功能，以下是 Kong 的 nginx 简要配置：

#### **Kong 原生插件：**

* rate-limiting限流插件；

* file-log 本地日志存储；
* acl 访问控制列表；
* key_auth 身份验证；
* 自定义插件;
* 灰度发布插件;
* rate-limiting-agent插件;

rate-limiting，rate-limiting-agent 与 key_auth 结合实现按角色进行限流

![kong-rate-limit](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/kong-rate-limit.png)

我们将流量区分为：正常用户的流量，蜘蛛流量，恶意抓取的流量

1) 其中蜘蛛流量和用户流量是根据 UA 进行划分的，蜘蛛流量的 UA（User-Agent）上会带有特殊的标识，比方说 spider,bot 等；
2) 用户流量中根据访问行为分为了正常用户流量和恶意抓取的流量，对于我们网站而言，恶意抓取的流量的特点在于 ip 很散，但是 UA 不变，而且访问在短时间内突增；

#### **限流流程**

![kong-rate-limit-process](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/kong-rate-limit-process.png)

1) 通过 key_auth 插件根据 UA 的特殊标识,将蜘蛛流量和用户流量进行角色上的划分。
2) 在蜘蛛角色的路由上设置 rate-limiting 限流插件，对蜘蛛的流量进行限流，限流值的设定是通过压测以及长期观察前端请求数与后端容量得到的结果。
3) 用户角色中含有正常用户的流量和恶意抓取的流量，我们认为同一个 UA 的请求属于一个用户，而在短时间内同一个 UA 流量突增的请求属于恶意流量，因此对用户角色设置了 rate-limit-agent 限流插件，限制同一个 UA 单位时间的请求量。

#### **Kong vs Zuul vs Tyk**

1) Kong是在 Nginx 中运行的 Lua 程序。得益于 Nginx 的性能优势，Kong 相比于其它的开源 API 网关来说，性能方面是最好的。由于大中型公司对于 Nginx 运维能力都比较强，所以选择 Kong 作为 API 网关，无论是在性能还是在运维的把控力上，都是比较好的选择；
2) Zuul是 Spring Cloud 全家桶中的成员，如果你已经使用了 Spring Cloud 中的其他组件，那么也可以考虑使用 Zuul 和它们无缝集成。不过，Zuul1 因为采用同步阻塞模型，所以在性能上并不是很高效，而 Zuul2 推出时间不长，难免会有坑。但是 Zuul 的代码简单易懂，可以很好地把控，并且你的系统的量级很可能达不到 Netfix 这样的级别，所以对于 Java 技术栈的团队，使用 Zuul 也是一个不错的选择；
3) Tyk是一种 Go 语言实现的轻量级 API 网关，有着丰富的插件资源，对于 Go 语言栈的团队来说，也是一种不错的选择；
