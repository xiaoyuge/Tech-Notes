## **负载均衡**

负载均衡从形式上都可以分为两种：四层负载均衡和七层负载均衡
- 四层负载均衡的优势是性能高，七层负载均衡的优势是功能强
- 做多级混合负载均衡，通常应该是低层负载均衡在前，高层负载均衡在后

我们所说的“四层”“七层”指的是经典的OSI七层模型中的第四层传输层和第七层应用层

所说的“四层负载均衡”其实是多种均衡器工作模式的统称，“四层”是说这些工作模式的共同特点是维持同一个TCP连接，而不是说它只工作在第四层。事实上，这些模式主要都工作在第二层（数据链路层，改写MAC地址）和第三层（网络层，改写IP地址）上，单纯只处理第四层（传输层，可以改写TCP、UDP等协议的内容和端口）的数据无法做到负载均衡的转发，因为OSI的下三层是媒体层（MediaLayer），上四层是主机层（HostLayer），既然流量都已经到达目标主机上了，也就谈不上什么流量转发，最多只能做代理。但出于习惯和方便，现在几乎所有的资料都把它们统称为四层负载均衡

几种常见的四层负载均衡工作模式
（1）数据链路层负载均衡
数据链路层负载均衡所做的工作，是修改请求的数据帧中的MAC目标地址，让用户原本发送给负载均衡器的请求的数据帧，被二层交换机根据新的MAC目标地址转发到服务器集群中对应的服务器（后文称为“真实服务器”，RealServer）的网卡上，这样真实服务器就获得了一个原本目标并不是发送给它的数据帧。由于二层负载均衡器在转发请求过程中只修改了帧的MAC目标地址，不涉及更上层协议（没有修改Payload的数据），所以在更上层（第三层）看来，所有数据都是未曾改变过的\
![data-link-balance](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/data-link-balance.png)

约束
1.由于第三层的数据包，即IP数据包中包含了源（客户端）和目标（均衡器）的IP地址，只有真实服务器保证自己的IP地址与数据包中的目标IP地址一致，这个数据包才能被正确处理。因此，使用这种负载均衡模式时，需要把真实物理服务器集群中所有机器的虚拟IP地址（VirtualIPAddress，VIP）配置成与负载均衡器的虚拟IP一样，才能使经均衡器转发后的数据包在真实服务器中顺利地使用
2.在网络侧受到的约束也很大，二层负载均衡器直接改写目标MAC地址的工作原理决定了它与真实服务器的通信必须是二层可达的，通俗地说就是必须位于同一个子网当中，无法跨VLAN

优势
也正是因为实际处理请求的真实物理服务器IP和数据请求中的目的IP是一致的，所以响应结果就不再需要通过负载均衡器进行地址交换，而是可将响应结果的数据包直接从真实服务器返回给用户的客户端，避免负载均衡器网卡带宽成为瓶颈，因此数据链路层负载均衡的效率是相当高的


所以，优势（效率高）和 劣势（不能跨子网）共同决定了数据链路层负载均衡最适合作为数据中心的第一级

（2）网络层负载均衡
根据OSI七层模型，在第三层网络层传输的单位是分组数据包（Packet），这是一种在分组交换网络（Packet Switching Network，PSN）中传输的结构化数据单位。以IP协议为例，一个IP数据包由头部（Header）和荷载（Payload）两部分组成，Header的长度最大为60字节，其中包括20字节的固定数据和最长不超过40字节的可选数据。按照IPv4标准，一个典型的分组数据包的Header部分具有如下表所示的结构\
![network-package](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/network-package.png)

无须过多关注表格中的其他信息，只要知道在IP分组数据包的Header中带有源和目标的IP地址即可。源和目标IP地址说明了数据是从分组交换网络中哪台机器发送到哪台机器的，我们可以沿用与二层改写MAC地址相似的思路，通过改变这里面的IP地址来实现数据包的转发。具体有两种常见的修改方式：

1.第一种是保持原数据包不变，新创建一个数据包：把原数据包的Header和Payload整体作为新数据包的Payload，并在这个新数据包的Header中写入真实服务器的IP作为目标地址，然后把它发送出去。经过三层交换机的转发，真实服务器收到数据包后，必须在接收入口处设计一个针对性的拆包机制，把由负载均衡器自动添加的那层Header扔掉，还原出原数据包来进行使用。这样，真实服务器就同样拿到了一个原本不是发给它（目标IP不是它）的数据包，达到了流量转发的目的，这种方式也成为“IP隧道（IP Tunnel）”。\
![ip-channel-balance](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/ip-channel-balance.png)

约束
1.第一个缺点是它要求真实服务器必须支持“IP隧道协议”（IPEncapsulation），即它得学会自己拆包扔掉一层Header，这个其实并不是什么大问题，现在几乎所有的Linux系统都支持IP隧道协议；
2.另外一个缺点是这种模式仍必须通过专门的配置，必须保证所有的真实服务器与负载均衡器有相同的虚拟IP地址，因为回复该数据包时，需要使用这个虚拟IP作为响应数据包的源地址，这样客户端收到这个数据包时才能正确解析。这个限制就相对麻烦一些，它与“透明”的原则冲突，需由系统管理员介入

优势
1.尽管因为要封装新的数据包，IP隧道转发模式的效率比直接路由模式的效率低，但由于并没有修改原数据包中的任何信息，所以IP隧道转发模式仍然具备三角传输的特性，即负载均衡器转发来的请求，可以由真实服务器去直接应答，无须经过负载均衡器原路返回
2.而且由于IP隧道工作在网络层，所以可以跨越VLAN，因此摆脱了直接路由模式中网络侧的约束

2.第二种修改方式改变目标数据包（NAT模式）：直接修改数据包Header中的目标地址，修改后原本由用户发给负载均衡器的数据包也会被三层交换机转发到真实服务器的网卡上，而且因为没有经过IP隧道的额外包装，也就无须再拆包了。但问题是是这种模式是通过修改目标IP地址才到达真实服务器的，如果真实服务器直接将应答包返回客户端，即这个应答数据包的源IP是真实服务器的IP，也即均衡器修改以后的IP地址，则客户端不可能认识该IP，自然就无法正常处理这个应答了。因此，只有让应答流量继续回到负载均衡器，由负载均衡器把应答包的源IP改回自己的IP，再发给客户端，才能保证客户端与真实服务器之间的正常通信\
![nat-balance](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/nat-balance.png)

劣势
在流量压力比较大的时候，NAT模式的负载均衡会带来较大的性能损失，比起直接路由和IP隧道模式，甚至会出现数量级上的下降。这点是显而易见的，由负载均衡器代表整个服务集群来进行应答，各个服务器的响应数据都会互相争抢均衡器的出口带宽

还有一种更加彻底的NAT模式：即负载均衡器在转发时，不仅会修改目标IP地址，还会修改源IP地址，这样源地址就改成负载均衡器自己的IP，称作SourceNAT（SNAT）。这样做的好处是真实服务器无须配置网关就能够让应答流量经过正常的三层路由回到负载均衡器上，做到彻底的透明。但是缺点是由于做了SNAT，真实服务器处理请求时就无法拿到客户端的IP地址，从真实服务器的视角来看，所有的流量都来自于负载均衡器，这样有一些需要根据目标IP进行控制的业务逻辑就无法进行了

（3）应用层负载均衡
前面介绍的四层负载均衡工作模式都属于“转发”，即直接将承载着TCP报文的底层数据格式（IP数据包或以太网帧）转发到真实服务器上，此时客户端与响应请求的真实服务器维持着同一条TCP通道。但工作在四层之后的负载均衡模式就无法再转发了，只能代理，此时真实服务器、负载均衡器、客户端三者之间由两条独立的TCP通道来维持通信\
![forward-proxy](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E4%BA%92%E8%81%94%E7%BD%91%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/resources/forward-proxy.png)


“代理”这个词，根据“哪一方能感知到”的原则，可以分为“正向代理”“反向代理”和“透明代理”三类。
1.正向代理就是我们通常简称的代理，指在客户端设置的，代表客户端与服务器通信的代理服务，它是客户端可知，而对服务器透明的；
2.反向代理是指在服务器侧设置的，代表真实服务器与客户端通信的代理服务，此时它对客户端来说是透明的；
3.至于透明代理是指对双方都透明的，配置在网络中间设备上的代理服务，譬如，架设在路由器上的透明翻墙代理；

七层负载均衡器属于反向代理的一种
如果只论网络性能，七层负载均衡器肯定比不过四层负载均衡器，原因如下
1.它比四层负载均衡器至少多一轮TCP握手；
2.有着跟NAT转发模式一样的带宽问题（响应需要统一通过负载均衡器）；
3.通常要耗费更多的CPU，因为可用的解析规则远比四层丰富；

所以如果用七层负载均衡器去做下载站、视频站这种流量应用是不合适的，起码不能作为第一级均衡器。但是，如果网站的性能瓶颈不是网络性能，而是整个服务集群对外所体现出来的服务性能，那么七层负载均衡器就有它的用武之地了。因为七层负载均衡器工作在应用层，可以感知应用层通信的具体内容，往往能够做出更明智的决策，玩出更多的花样。

常见负载均衡策略
* 轮询均衡（RoundRobin）：每一次来自网络的请求轮流分配给内部的服务器，从1至N然后重新开始。此种均衡算法适合于服务器集群中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。
* 权重轮询均衡（WeightedRoundRobin）：根据服务器的不同处理能力，给每个服务器分配不同的权重值，使其能够接受相应权值数的服务请求。譬如：设置服务器A的权值为1，B的权值为3，C的权值为6，则服务器A、B、C将分别接收到10%、30%、60%的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。
* 随机均衡（Random）：把来自客户端的请求随机分配给内部的多个服务器，在数据量足够大的场景下能达到相对均衡的分布；
* 权重随机均衡（WeightedRandom）：此种均衡算法类似于权重轮询算法，不过在分配处理请求时是随机选择的过程；
* 一致性哈希均衡（ConsistencyHash）：将请求中的某些数据（可以是MAC、IP地址，也可以是更上层协议中的某些参数信息）作为特征值来计算需要落在的节点，算法一般会保证同一个特征值每次都一定落在相同的服务器上。这里的一致性是指保证当服务集群某个真实服务器出现故障时，只影响该服务器的哈希值，而不会导致整个服务器集群的哈希键值重新分布；
* 响应速度均衡（ResponseTime）：负载均衡设备对内部各服务器发出一个探测请求（例如Ping），然后根据内部各服务器对探测请求的最快响应时间来决定哪一台服务器响应客户端的服务请求。此种均衡算法能较好地反映服务器的当前运行状态，但最快响应时间仅仅指的是负载均衡设备与服务器之间的最快响应时间，而不是客户端与服务器之间的最快响应时间；
* 最少连接数均衡（LeastConnection）：客户端的每一次请求服务在服务器停留的时间可能会有较大差异，随着工作时间增加，如果采用简单的轮询或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不平衡，并不能达到真正的负载均衡。最少连接数均衡算法会对内部需负载的每一台服务器有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，使负载更加均衡。此种均衡策略适合长时处理的请求服务，如FTP传输；