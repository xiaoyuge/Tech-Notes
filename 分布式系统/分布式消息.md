## **分布式消息中间件**

### **1)消息模型**

- 1.1 **队列模型( queue，point-to-point)**：消息生产者生产消息发送到queue，然后消息消费者从queue中取出并且消费消息，消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，这些**消费者之间实际上是竞争关系**，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。因此一般实际使用中，只有一个消息生产者和一个消息消费者；
- 1.2 **发布订阅模型（publisher-subcriber）**：如果只有一类发送者，发送者将产生的消息实体按照不同的主题（Topic）分发到不同的逻辑队列。每种主题队列对应于一类接收者。这就变成了典型的发布订阅模型。在该模型，三个角色一般称为发布者（Publisher），分布式队列（Queue），订阅者（Subscriber），和点对点方式不同，发布到topic的消息会被所有订阅者消费；

上述两种模型的主要区别在于：是否能重复消费!

### **2）业界开源的分布式消息队列，按照是否有独立部署进程来看，可以分为两个大类：**

- 2.1 **Broker类的分布式消息队列**：是指有独立部署进程的分布式服务，即发送者把消息发布到Broker进程，再由Broker进程推（或者是拉）给订阅者，代表有RabbitMq、RocketMq、Kafka、ActiveMq等；
- 2.2 **Brokerless类的消息队列**：主要采用api的方式，编译到应用程序中，在应用程序间进行点对点的通信，代表的有ZeroMq、Akka（actor模型）等；

也即，基于消息的系统模型，不一定需要broker(消息队列服务端)，我们之所以要设计一个消息队列，并且配备broker，主要做两件事情：一个是消息的转储，在更合适的时间点投递，或者通过一系列手段辅助消息最终能送达消费者；一个是规范一种范式和通用的模式，以满足解耦、最终一致性、错峰等需求；

### **3）消息队列应用场景：**

1) **异步处理（解耦）**：解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心流程，而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。换句话说，基于消息的模型，关心的是“通知”，而非“处理”；

2) **最终一致性**：主要是用“记录”和“补偿”的方式。在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。成功就可以把记录的东西清理掉了，对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止。在经典的银行转账的例子中，系统在A扣钱成功的情况下，把要给B“通知”这件事记录在库里（为了保证最高的可靠性可以把通知B系统加钱和扣钱成功这两件事维护在一个本地事务里），通知成功则删除这条记录，通知失败或不确定则依靠定时任务补偿性地通知我们，直到我们把状态更新成正确的为止；

3) **广播**：消息队列的基本功能之一是进行广播。如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。有了消息队列（使用发布订阅模式），我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量；

4) **削峰与流控（消息堆积能力）**：上下游对于业务的处理能力是不同的，如果没有消息队列，每当上下游系统处理能力有差距的时候，都需要单独开发一套逻辑来处理定时、拥塞等一系列问题。所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。比如，Web前端每秒承受上千万的请求，并不是什么神奇的事情，只需要加多一点机器，再搭建一些LVS负载均衡设备和Nginx等即可。但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。由于成本的考虑，我们不能奢求数据库的机器数量追上前端；

### **4）实现一个消息队列的基本功能**

1. **RPC通信**：所谓消息队列，无外乎两次RPC加一次转储，当然需要消费端最终做消费确认的情况是三次RPC，既然是RPC，就必然涉及到负载均衡、服务发现、通信协议、序列化协议等一些列问题，建议不重复造轮子复用现有成熟的RPC框架来实现。简单来讲，服务端提供两个RPC服务，一个用来接收消息，一个用来确认消息收到。并且做到不管哪个server收到消息和确认消息，结果一致即可。当然这中间可能还涉及跨IDC的服务的问题。这里和RPC的原则是一致的，尽量优先选择本机房投递；

2. **高可用**：所有的高可用，是依赖于RPC和存储的高可用来做的。消息队列的高可用，只要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的，这样就把消息队列的可用性，转交给RPC框架来处理。保证幂等最简单的方式莫过于共享存储，broker多机器共享一个DB或者一个分布式文件/kv系统，则处理消息自然是幂等的。就算有单点故障，其他节点可以立刻顶上；

3. **服务端承载消息堆积的能力**：消息到达服务端如果不经过任何处理就到接收者了，broker就失去了它的意义。为了满足我们错峰/流控/最终可达等一系列需求，把消息存储下来，然后选择时机投递就显得是顺理成章的了。这个存储可以做成很多方式。比如存储在内存里，存储在分布式KV里，存储在磁盘里，存储在数据库里等等。但归结起来，主要有持久化和非持久化两种。持久化的形式能更大程度地保证消息的可靠性（如断电等不可抗外力），并且理论上能承载更大限度的消息堆积（外存的空间远大于内存），但并不是每种消息都需要持久化存储。很多消息对于投递性能的要求大于可靠性的要求，且数量极大（如日志）。这时候，消息不落地直接暂存内存，尝试几次failover，最终投递出去也未尝不可。市面上的消息队列普遍两种形式都支持。当然具体的场景还要具体结合公司的业务来看；

4. **存储子系统的选择**：如果需要数据落地的情况下各种存储子系统如何选择？理论上，从速度来看，文件系统 > 分布式KV（持久化）> 分布式文件系统 > 数据库，而可靠性却截然相反。还是要从支持的业务场景出发作出最合理的选择，如果你们的消息队列是用来支持支付/交易等对可靠性要求非常高，但对性能和量的要求没有这么高，而且没有时间精力专门做文件存储系统的研究，DB是最好的选择，但是DB受制于IOPS，如果要求单broker 5位数以上的QPS性能，基于文件的存储是比较好的解决方案；

5. **消费关系解析**：现在我们的消息队列初步具备了转储消息的能力。下面一个重要的事情就是解析发送接收关系，进行正确的消息投递了。市面上的消息队列定义了一堆让人晕头转向的名词，如JMS 规范中的Topic/Queue，Kafka里面的Topic/Partition/ConsumerGroup，RabbitMQ里面的Exchange等等。抛开现象看本质，无外乎是单播与广播的区别。所谓单播，就是点到点；而广播，是一点对多点。当然，对于互联网的大部分应用来说，组间广播、组内单播是最常见的情形。消息需要通知到多个业务集群，而一个业务集群内有很多台机器，只要一台机器消费这个消息就可以了。当然这不是绝对的，很多时候组内的广播也是有适用场景的，如本地缓存的更新等等。另外，消费关系除了组内组间，可能会有多级树状关系.所以，一般比较通用的设计是支持组间广播，不同的组注册不同的订阅。组内的不同机器，如果注册一个相同的ID，则单播；如果注册不同的ID(如IP地址+端口)，则广播。至于广播关系的维护，一般由于消息队列本身都是集群，所以都维护在公共存储上，如config server、zookeeper等。维护广播关系所要做的事情基本是一致的：发送关系的维护 和 发送关系变更时的通知；

### **消息服务的Qos**

在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：

1. At most once（至多一次）：消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失；
2. At least once（至少一次）：消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现；
3. Exactly once（only once，恰好一次）：消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级；

QoS（Quality of Service）指代消息传输的服务质量，它包括以下级别：
QoS0 代表最多分发一次
QoS1 代表至少达到一次
QoS2 代表仅分发一次
注意：QoS 越好，性能越差

一个主流消息队列的设计范式里，应该是保证不丢消息的前提下，尽量减少重复消息，不保证消息顺序。我们现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复。

#### **重复消息处理**

1. 如何鉴别消息重复，并幂等的处理重复消息

    关于鉴别消息重复：每一个消息应该有它的唯一身份。不管是业务方自定义的，还是根据IP/PID/时间戳生成的MessageId，如果有地方记录这个MessageId，消息到来是能够进行比对就能完成重复的鉴定。数据库的唯一键/bloom filter/分布式KV中的key，都是不错的选择；

    关于重复消息的处理：种种原因重复消息还是来到了，除了ID判重的方案之外，还有一种方案是版本号方案，也即每个消息自带一个版本号，下游对于每次消息的处理，同时维护一个版本号，每次只接受比当前版本号大的消息；

2. 一个消息队列如何尽量减少重复消息的投递；

broker端减少重复消息的方案：

    1. broker记录MessageId，直到投递成功后清除，重复的ID到来不做处理，这样只要发送者在清除周期内能够感知到消息投递成功，就基本不会在server端产生重复消息；
    2. 对于server投递到consumer的消息，由于不确定对端是在处理过程中还是消息发送丢失的情况下，有必要记录下投递的IP地址。决定重发之前询问这个IP，消息处理成功了吗？如果询问无果，再重发；

#### **消息如何保证顺序**

1. 基于版本号的办法：参考TCP/IP协议，如果想让乱序的消息最后能够正确的被组织，那么就应该只接收比当前版本号大一的消息。并且在一个session周期内要一直保存各个消息的版本号；但用版本号的最大问题有两个，一个是对发送方必须要求消息带业务版本号，一个是下游必须存储消息的版本号，对于要严格保证顺序的；还不能只存储最新的版本号的消息，要把乱序到来的消息都存储起来。而且必须要对此做出处理。试想一个永不过期的"session"，那么中间环节的所有存储就必须保留，直到在某个版本号之前的版本一个不丢的到来，成本太高；

2. 状态机：如果消息没有版本号，该怎么解决？此时业务方只需要自己维护一个状态机，定义各种状态的流转关系，如果收到了违反状态机规则的消息，在消息不丢失和上游业务正确的前提下。要么是消息发重了，要么是顺序到达反了。这时消费者只需要把“我不能处理这个消息”告诉投递者，要求投递者过一段时间重发即可。而且重发一定要有次数限制，比如5次，避免死循环，就解决了；

述通用的版本号/状态机/ID判重解决方案里，哪些是消息队列该做的、哪些是消息队列不该做业务方处理的呢？其实这里没有一个完全严格的定义，但回到我们的出发点，我们保证不丢失消息的情况下尽量少重复消息，消费顺序不保证。那么重复消息下和乱序消息下业务的正确，应该是由消费方保证的，我们要做的是减少消息发送的重复。

合格的消息队列必须支持的几个特型：

1. 不丢消息；
2. 服务可靠性；
3. 性能；

### **RabbitMQ**

RabbitMQ 是使用一种比较小众的编程语言：Erlang语言编写，RabbitMQ 就像它的名字中的兔子一样：轻量级、迅捷，RabbitMQ 是一个相当轻量级的消息队列，非常容易部署和使用

#### **消息模型**

队列模型，那如何实现消息的多个消费者消费的问题？答案是使用 exchange 模块
在 RabbitMQ 中，Exchange 位于生产者和队列之间，生产者并不关心将消息发送给哪个队列，而是将消息发送给 Exchange，由 Exchange 上配置的策略来决定将消息投递到哪些队列中。同一份消息如果需要被多个消费者来消费，需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相地实现新发布 - 订阅模型中，“一份消息数据可以被多个订阅者来多次消费”这样的功能

#### **特色：**

1. 非常灵活的路由配置：和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个 Exchange 模块（对 AMQP 协议规范的实现），这个Exchange 模块的作用和交换机也非常相似，根据配置的路由规则将生产者发出的消息分发到不同的队列中。路由的规则也非常灵活，甚至你可以自己来实现路由规则。基于这个 Exchange，可以产生很多的玩儿法，比如基于此实现发布订阅模式；

2. 客户端编程语言支持丰富：RabbitMQ 的客户端支持的编程语言大概是所有消息队列中最多的，如果你的系统是用某种冷门语言开发的，那你多半可以找到对应的 RabbitMQ 客户端；

#### **问题：**

1. 对消息堆积的支持不好：在它的设计理念里面，消息队列是一个管道，大量的消息积压是一种不正常的情况，应当尽量去避免。当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降；

2. 性能不够好：依据硬件配置的不同，它大概每秒钟可以处理几万到十几万条消息。其实，这个性能也足够支撑绝大多数的应用场景，不过，如果你的应用对消息队列的性能要求非常高，那不要选择 RabbitMQ；

3. 二次开发和扩展成本高：RabbitMQ使用的编程语言 Erlang，这个编程语言不仅是非常小众的语言，更麻烦的是，这个语言的学习曲线非常陡峭，如果有需要基于RabbitMQ做一些扩展和二次开发，需要慎重考虑一下可持续维护的问题；

### **RocketMQ**

阿里巴巴在 2012 年开源的消息队列产品，后来捐赠给 Apache 软件基金会，2017 正式毕业，成为 Apache 的顶级项目，java语言编写

#### **消息模型**

发布-订阅模型

![rocketmq-pub-sub-model](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/resources/rocketmq-pub-sub-model.png)

核心概念：生产者、消费者组、消费者、主题、队列

1. 每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。需要注意的是，RocketMQ只在队列上保证消息的有序性，主题不保证消息的严格顺序；

2. 订阅者的概念是通过消费组（Consumer Group）来体现，每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响；

3. 消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费主题的一部分消息；

在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，我们在使用消息队列的时候，丢消息的原因大多是由于消费位置处理不当导致的

一个消费组在一个主题下的多个队列并发消费消费无法保证消息的顺序性，但如果业务要求保证顺序，如何解决？

一种解题思路：业务上的顺序，通常并不是要求全局有序，而是针对某个业务实体的消息需要保证顺序，但不同业务实体的顺序通常不需要保证顺序

所以，可以按照业务实体 ID 进行一致性 hash 算法处理，计算出要发布的队列 id，这样就能保证某个业务实体的消息总是被发送到同一个队列，而同一个队列是可以保证顺序的

#### **优点：**

1. 不错的性能，稳定性和可靠性，具备一个现代的消息队列应该有的几乎全部功能和特性；
2. 非常活跃的中文社区；
3. 在线响应时延低：RocketMQ 对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ；
4. 性能高：RocketMQ 的性能比 RabbitMQ 要高一个数量级，每秒钟大概能处理几十万条消息；

#### **劣势：**

作为国产的消息队列，相比国外的比较流行的同类产品，在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹

### **Kafka**

Kafka 最早是由 LinkedIn 开发，目前也是 Apache 的顶级项目。Kafka 最初的设计目的是用于处理海量的日志。scala语言编写

#### **消息模型**

发布-订阅模型

Kafka的消息模型和RocketMQ是完全一样的，唯一的区别是，在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能没有任何区别

kafka的Ack 参数（request.required.asks）决定了消息传递的可靠程度
Acks这个参数是生产者客户端的重要配置，发送消息的时候就可设置这个参数。该参数有三个值可配置：0、1、All 。

1. 第一种是设为0意思是生产者把消息发送出去之后，之后这消息是死是活咱就不管了，有那么点发后即忘的意思，说出去的话就不负责了。不负责自然这消息就有可能丢失，那就把可用性也丢失了；
2. 第二种是设为1意思是生产者把消息发送出去之后，这消息只要顺利传达给了Leader，其他Follower有没有同步就无所谓了。存在一种情况，Leader刚收到了消息，Follower还没来得及同步Broker就宕机了，但生产者已经认为消息发送成功了，那么此时消息就丢失了。
设为1是Kafka的默认配置，可见Kafka的默认配置也不是那么高可用，而是对高可用和高吞吐量做了权衡折中；
3. 第三种是设为All（或者-1）意思是生产者把消息发送出去之后，不仅Leader要接收到，ISR列表中的Follower也要同步到，生产者才会任务消息发送成功；
进一步思考， Acks=All 就不会出现丢失消息的情况吗？答案是否。当ISR列表只剩Leader的情况下， Asks=All 相当于 Asks=1 ，这种情况下如果节点宕机了，还能保证数据不丢失吗？因此只有在 Asks=All并且有ISR中有两个副本的情况下才能保证数据不丢失

#### **kafka保证高可用**

Kafka0.8以后，提供了HA机制，就是replica副本机制，每个Partition的数据都会同步到其他机器上，形成多个replica副本。然后所有replica会选举出一个leader出来，生产和消费都和这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候直接读leader上数据即可。kafka会均匀的把一个partition的所有replica分布到不同的机器上，这样可以提高容错性。kafka2.8.0版本之前通过zookeeper管理各个节点，2.8.0版本实现了Raft分布式一致性机制，可以脱离zookeeper独立运行

#### **kafka的分区策略**

1. 轮询策略：默认的分区策略，非常优秀的负载均衡表现，总是能保证消息最大限度地被平均分配到所有分区上；
2. 随机策略：实现随机策略版的partition方法；
3. 按消息键保序策略：也称key-ordering策略，可以保证同一个key的所有消息都进入到相同的partition里，由于每个partition下的消息处理是有顺序的，因此称为消息键保序策略；
4. 自定义分区策略：在编写生产者程序时，可以编写一个具体的类实现org.apache.kafka.clients.producer.partition接口，这个接口只定义了partition()和close()两个方法，通常只实现partition()方法即可，同时还需要设置partitioner.class参数为你自己实现类的全限定名；

#### **优势**

1. Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域，几乎所有的相关开源软件系统都会优先支持 Kafka
2. 设计上大量使用了批量和异步的思想，这种设计使得 Kafka 能做到超高的性能。Kafka 的性能，尤其是异步收发的性能，是三者中最好的，但与 RocketMQ 并没有量级上的差异，大约每秒钟可以处理几十万条消息；

#### **问题**

Kafka这种**异步批量**的设计带来的问题是，它的同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。

比如发消息，同样是用户调用了send()方法，RockMQ它会直接把这个消息发出去，而Kafka会把这个消息放到本地缓存里面，然后择机异步批量发送。所以，RocketMQ的时延更小一些，而Kafka的吞吐量更高。所以，Kafka不太适合在线业务场景

#### **上述三个消息队列的使用场景**

1. 如果说，消息队列并不是你将要构建系统的主角之一，你对消息队列功能和性能都没有很高的要求，只需要一个开箱即用易于维护的产品，可以考虑使用 RabbitMQ；
2. 如果你的系统使用消息队列主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，那 RocketMQ 的低延迟和金融级的稳定性是你需要的；
3. 如果你需要离线处理海量的消息，比如日志收集、监控信息或前端埋点这类数据，或是你的应用场景大量使用了大数据和流计算相关的开源产品，那Kafka是最适合你的消息队列；

#### **确保消息可靠传递的机制**

![message-reliable-deliver](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/resources/message-reliable-deliver.png)

1. **生产阶段**：消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。你在编写发送消息代码时需要注意正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失；

2. **存储阶段**：对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失；

3. **消费阶段**：采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。在编写消费代码时需要注意的是，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认；

#### **broker 和 consumer接收到重复消息如何处理**

我们现在常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复

既然消息队列无法保证消息不重复，就需要我们的消费代码能够接受“消息是可能会重复的”这一现状，然后，通过一些方法来消除重复消息对业务的影响

消费端处理方法

1. 保证幂等性：一个幂等的方法，使用同样的参数，对它进行多次调用和一次调用，对系统产生的影响是一样的。所以，对于幂等的方法，不用担心重复执行会对系统造成任何改变。如果我们系统消费消息的业务逻辑具备幂等性，那就不用担心消息重复的问题了，因为同一条消息，消费一次和消费多次对系统的影响是完全一样的。也就可以认为，消费多次等于消费一次。从对系统的影响结果来说：At least once + 幂等消费 = Exactly once；

2. 业务无法保证非幂等，那就做消息去重：根据业务ID(标识消息全局唯一性)，去查询是否消费过此消息了，消费了，则抛弃，否则就消费，需要注意的是，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug，需要考虑用分布式事务或分布式锁来解决；

#### **消息积压如何处理**

- 发送端：增加批量或者是增加并发；
- 消费端：增加并发，并且需要同步扩容分区数量，否则起不到效果

对于系统发生消息积压的情况，需要先解决积压，再分析原因，毕竟保证系统的可用性是首先要解决的问题。快速解决积压的方法就是通过水平扩容增加 Consumer 的实例数量

### **Kafka vs RocketMQ**

#### **数据可靠性**

RocketMQ支持异步实时刷盘，同步刷盘，异步Replication，同步Replication
Kafka使用异步刷盘方式，异步Replication，同步 Replication
总结：RocketMQ的同步刷盘在单机可靠性上比Kafka更高，不会因为操作系统Crash，导致数据丢失

### **消费能力跟不上的解决思路**

1. 增加partion的数量；
2. 消费端改批量处理：事件本地先聚合一段时间
3. 消费端同步改异步：下游是否允许消息丢失或失败，不允许的话需要处理失败的消息，考虑补偿机制

### **MQTT  VS 传统消息中间件**

传统的消息中间件，例如消息队列 RocketMQ 版、消息队列 Kafka 版等都是面向微服务大数据等领域，负责消息的存储和转发，消息的生产者和消费者都是服务端应用。这种设计很适合服务端技术栈固定、语言平台固定的场景。而移动互联网和 IoT 领域则有所不同，这类场景更侧重于多语言多平台的海量设备接入，消息的生产和消费过程的业务属性很突出，传统的消息中间件并不适合这些领域

![mqtt-vs-mq](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/resources/mqtt-vs-mq.png)

场景示例

![mqtt-apply-env](https://github.com/xiaoyuge/Tech-Notes/blob/main/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/resources/mqtt-apply-env.png)