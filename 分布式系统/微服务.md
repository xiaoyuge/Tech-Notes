**微服务**

**SOA**\
不是一种技术，也不是软件，而是**一种思想，一种架构风格，一种面向服务的IT架构风格，一种IT系统咨询和建设的方法论**

**目标**：通过服务的集成和编排，快速支持业务迭代和创新

**核心要素**：\
**标准化**（指标准化通讯协议和数据交换格式，这样服务之间可以互操作，且服务可以复用了）\
**松耦合**（也即高内聚，则要求服务拆分边界要合理）\
**可复用**（则要求服务的架构和数据模型可扩展性好）

但 SOA 在实施的时候（或在当时的背景下），是为了解决企业 IT 建设烟囱式的建设问题（成本浪费、数据孤岛、没有业务沉淀无法持续发展等），完成异构系统的互联互通，所以在**落地实施的时候【歪】了**，只解决了历史系统的集成互通问题，但因为历史系统（或服务）没有按照 SOA 的理念进行升级改造（标准化、松耦合、可复用），因此还是无法支持业务的持续快速迭代和创新。

基于 SOA 的应用构建过程：\
1.服务建模：主要服务识别和颗粒度确认；\
2.服务封装：主要是对服务进行标准化描述；\
3.服务治理：主要是通过 esb 等基础设施实现服务的注册、发现等；\
4.服务编排：主要是根据业务流程，对服务进行编排和组装；\
5.应用交付：主要是完成服务部署；

**企业服务总线ESB**:\
是SOA架构风格的一种实现方式，是实现SOA治理的重要支撑平台，是SOA解决方案的核心,提供可靠消息传输、服务接入、**协议转换、数据格式转换**、基于内容的路由等功能，屏蔽了服务的物理位置，协议和数据格式
——但这样很重，esb很容易成为瓶颈，比如ESB的落地实现方案mule esb

**WebService**:\
是一种对于SOA架构风格的实现方式，但SOA架构风格并不一定只能通过WebService来实现，但因为它的特性和厂商的支持力度，使得WebService成为了实现SOA实现技术的事实标准

WebService三大基本元素：SOAP、WSDL 和 UDDI \
**SOAP（simple object access protocal）**：基于XML和HTTP ，其通过XML来实现消息描述(如何进行数据交换)，然后再通过HTTP实现消息传输（如何进行数据传输）;\
**WSDL（web service description language）**：web 服务描述语言，服务提供者通过其来描述来告诉服务请求者如何访问自己，包括服务所提供的操作、如何访问服务、服务位于何处；\
**UDDI（universal description,discovery and integration）**：一种目录服务，用来注册和发现服务;

**web service特点**：
1.**自包含**：不需要附加任何软件，只要支持 Http 和 xml 就行；
2.**自描述**：不需要知道除了请求和响应消息格式和内容之外的其他信息；
3.**跨平台和跨语言**：服务提供和调用方可以在不同的平台用不同的语言实现；
4.**基于开放标准**：web service 基于 http 和 xml，这两个是业内标准；
5.**松耦合**:解耦了客户端和服务端；

**为什么web service很少使用**？
因为xml描述方式的冗余性，导致数据传输效率慢，性能差

**微服务**\
最早提出微服务架构概念的，是Fred George（@2012 3月）：Microservices Architecture-small,short lived services rather than SOA

**Mattin Fowler对微服务的定义**\
Microservices-the new architectual style，微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，**服务与服务间采用轻量级的通信机制互相协作**（通常是基于HTTP协议的RESTful API）。每个服务都围绕着具体业务进行构建，并且能够被独立的部署到生产环境、类生产环境等

微服务是一种通过多个小型服务的组合，来构建单个应用的架构风格，这些服务会围绕业务能力而非特定的技术标准来构建。**各个服务可以采用不同的编程语言、不同的数据存储技术、运行在不同的进程之中**。服务会采取轻量级的通讯机制和自动化的部署机制，来实现通讯与运维

Adrain Cockcroft（Netflix的云架构师，主导了Netflix从2009到2016年服务化拆分、从数据中心迁移到云平台、以及组织、流程、工具等的演进）对微服务的定义:\
Loosely coupled service oriented architecture with bounded contexts\
其中两个核心点：Loosely coupled 和 Bounded context，Loosely coupled表明，服务之间是松耦合的。\
什么叫松耦合？就是指服务能够被**独立更新（我理解是独立开发、测试、部署和运维）**，如果不能被独立更新，那证明服务就不是松耦合的。\
Bounded context，源于DDD(领域驱动设计)，表明对于服务而言，它的业务是独立的，我们不需要知道它的依赖者，根据接口就可以更新服务的代码

Neal Ford（TW的资深技术专家，《卓有成效的程序员》作者，也是TW技术雷达的发起者和维护者之一）对微服务的定义：\
Microservices are the first post DevOps revolution architecture\
这是第一次将微服务和DevOps紧密关联起来的版本，DevOps所涵盖的一系列文化、实践以及自动化的理念(CALMS)，是微服务演进过程中必不可少的先决条件。可以说，在传统的运维模式下，有效实现微服务架构几乎是不可能的，因为**微服务的实施需要自动化基础设施、自动化部署、自动化验证、以及利用有效的工具完成运维、监控、告警**等。而只有将DevOps与微服务紧密的结合起来，才能达到事半功倍的效果

**单体架构 VS 微服务架构**

先搞清楚一个思维误区：那就是单体架构是落后的系统架构风格，最终会被微服务所取代（错误的思维）

对于小型系统(不复杂的系统)，也就是用单台机器就足以支撑其良好运行的系统来说，这样的单体不仅易于开发、易于测试、易于部署，而且因为各个功能、模块、方法的调用过程，都是在进程内调用的，**不会发生进程间通讯，所以程序的运行效率也要比分布式系统更高**，完全不应该被贴上“落后”的标签

所以，当我们在讨论单体系统的缺陷的时候，必须基于软件的性能需求超过了单机，软件的开发人员规模明显超过了“2 Pizza Teams”范畴的前提下，这样才有讨论的价值

单体架构实际逻辑上从纵向分层和横向分模块的角度进行了拆分，并不完全是不可拆分的巨石一块

但单体系统的问题是这些逻辑拆分的代码都是运行在同一个进程里的，所有模块、方法的调用也都不需要考虑网络分区、对象复制这些麻烦事儿，也不担心因为数据交换而造成性能的损失。可是，在获得了进程内调用的简单、高效这些好处的同时，也就意味着，如果**在单体架构中，有任何一部分的代码出现了缺陷，过度消耗进程空间内的公共资源，那所造成的影响就是全局性的、难以隔离的**

首先，一旦架构中出现了内存泄漏、线程爆炸、阻塞、死循环等问题，就都将会影响到整个程序的运行，而不仅仅是某一个功能、模块本身的正常运作；而如果消耗的是某些更高层次的公共资源，比如端口占用过多或者数据库连接池泄漏，还将会波及到整台机器，甚至是集群中其他单体副本的正常工作。

其次，同样是因为所有代码都共享着同一个进程空间，如果代码无法隔离，那也就意味着，**我们无法做到单独停止、更新、升级某一部分代码**，因为不可能有“停掉半个进程，重启 1/4 个进程”这样不合逻辑的操作。所以，从动态可维护性的角度来说，单体系统也是有所不足的，对于程序升级、修改缺陷这样的工作，我们往往需要制定专门的停机更新计划，而且做灰度发布也相对会更加复杂

另外，由于自治和隔离能力的缺失，除了会带**来难以阻断错误传播、不便于动态更新程序**的问题，还会给带来**难以技术异构**等困难，技术异构的意思是说允许系统的每个模块，自由选择不一样的程序语言、不一样的编程框架等技术栈去实现。单体系统的技术栈异构不是一定做不到，比如 JNI 就可以让 Java 混用 C/C++，但是这也是很麻烦的事，是迫不得已下的选择

**微服务的粒度（边界）**

可以从两个方面来考虑，一个是从业务角度来考虑，根据领取驱动设计（DDD）的方法论，来识别微服务的边界（见技术笔记DDD），另外则可从非功能性、研发效率等方面来考虑微服务的粒度和拆分。

系统设计是一种创作，而不是应试，不可能每一位架构师设计的服务粒度全都相同，微服务的大小、边界不应该只有唯一正确的答案或绝对的标准，但是应该有个合理的范围，我们称其为微服务粒度的上下界。我们可以通过分析如果微服务的粒度太小或者太大会出现哪些问题，从而得出服务上下界应该定在哪里。

如果微服务粒度设计得过细，会存在如下几方面问题：\
1.从性能角度看，一次进程内的方法调用（仅计算调用，与方法具体内容无关），耗时在零（按方法完全内联的场景来计算）到数百个时钟周期（按最慢的虚方法调用无内联缓存要查虚表的场景来计算）之间。而**一次跨服务的方法调用里，网络传输、参数序列化和结果反序列化都是不可避免的**，耗时要达到毫秒级别，因此，服务粒度大小必须考虑到消耗在网络上的时间与方法本身执行时间的比例，避免设计得过于琐碎，客户端不得不多次调用服务才能完成一项业务操作，这点要求从功能设计上看微服务应该是完备的；\
2.从数据一致性角度看，每个微服务都有自己独立的数据源，如果多个微服务要协同工作，我们可以采用很多办法来保证它们处理数据的最终一致性，但**如果某些数据必须要求保证强一致性的话，那它们本身就应当聚合在同一个微服务中，而不是强行启用XA事务来实现**，因为参与协作的微服务越多，XA事务的可用性就越差。这点要求从数据一致性上看微服务应该是内聚（Cohesion）的；\
3.从服务的可用性角度看，服务之间是松散耦合的依赖关系，微服务架构中无法也不应该假设被调用的服务具有绝对的可用性，服务可能因为网络分区、软件重启升级、硬件故障等任何原因发生中断。如果两个微服务都必须依赖对方可用才能正常工作，那就应当将其合并到同一个微服务中（注意这里说的是“彼此依赖对方才能工作”，单向的依赖是必定存在的）。这点要求从依赖关系上看微服务应该是独立的；

综合以上，我们可以得出第一个结论：微服务粒度的下界是它至少应满足\
1.独立——能够独立发布、独立部署、独立运行与独立测试；\
2.内聚——强相关的功能与数据在同一个服务中处理；\
3.完备——一个服务包含至少一项业务实体与对应的完整操作；

如果微服务的粒度太大，会出现什么问题？从技术角度讲，并不会有什么问题，每个能正常工作的单体系统都能满足独立、内聚、完备的要求。**微服务的上界并非受限于技术，而是受限于人，更准确地说，受限于人与人之间的社交协作**。

软件项目中的沟通成本=n×(n–1)/2，n为参与项目的人数
按此公式计算，15人参与的项目，沟通成本大约是5人项目的十倍，150人参与的项目，沟通成本大约是5人项目的一千倍
康威定律约束了软件的架构与组织的架构要保持一致，所以微服务的上界应该与2PizzaTeam能够开发的最大程序规模保持一致

在上下界范围内，架构师会根据业务和团队的实际情况来灵活划定微服务的具体粒度。譬如下界的完备性要求微服务至少包含一项完整的业务，在不超过上界的前提下，要判断这个微服务包含两项、三项业务操作是否合理，需要根据这些操作本身是否有合理的逻辑关系来具体讨论


**微服务 VS SOA **

1.目标不同：SOA涉及的范围更广一些（比如公司级别），强调不同异构服务之间的集成、业务编排、历史应用集成等，这些服务的粒度一般较粗，典型代表是webservice 和 ESB；
微服务目的是通过有效拆分应用，实现敏捷开发和部署，在每个微小服务团队里，减少跨团队沟通，缩小变更和迭代影响的范围，并达到单一微服务更容易水平扩展的目的；\
2.部署方式不同：微服务将完整的应用拆分成多个细小的服务，通常使用敏捷扩容、缩容的Docker技术来实现自动化的容器管理，每个微服务运行在单一的进程里，微服务中的部署互相独立，互不影响；SOA服务化通常将多个业务服务通过组件化模块方式打包在一个War包里，然后统一部署在一个应用服务器上；\
3.服务粒度不同：微服务倡导将服务拆分成更细的粒度，通过多个服务组合来实现业务流程的处理，拆分到单一职责，甚至小到不能再进行拆分；SOA对粒度没有要求，在实践中通常是粗粒度；

**Service Mesh(服务网格)**：下一代的微服务架构\
定义\
A service mesh is a dedicated **infrastructure layer for handling service-to-service communication**. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh **is typically implemented as an array of lightweight network proxies that are deployed alongside application code**, without the application needing to be aware. (But there are variations to this idea, as we’ll see.)\
翻译：Service Mesh 是一个**基础设施层，用于处理服务间通信**。云原生应用有着复杂的服务拓扑，Service Mesh 保证请求可以在这些拓扑中可靠地穿梭。在实际应用当中，Service Mesh 通常是由**一系列轻量级的网络代理组成的，它们与应用程序部署在一起，但应用程序不需要知道它们的存在**。

关于这个定义有以下两个值得我们关注的核心点：\
1.“dedicated infrastructure layer”：Service Mesh 不是用来解决业务领域问题的，而是**一层专门的基础设施（中间件）**。
2.“service-to-service communication”：Service Mesh 的定位很简单也很清晰，就是**用来处理服务与服务之间的通讯**。
3.“reliable delivery of requests”：服务间通讯为什么需要特殊处理？因为网络是不可靠的，Service Mesh 的**愿景就是让服务间的请求传递变得可靠**。
4.“cloud native application”：Service Mesh 从一开始就是为现代化的云原生应用而生，瞄准了未来的技术发展趋势。
5.“network proxies”：具体 Service Mesh 应该怎么实现？典型方式都是**通过一组轻量级的网络代理，在应用无感知的情况下**偷偷就把这事给干了。
6.“deployed alongside application code”：这些**网络代理一定是跟应用部署在一起**，一对一近距离贴心服务（比房产中介专一得多）；否则，如果应用与代理之间也还是远程不靠谱通讯，这事儿就没完了。

Service Mesh 这个基础设施层的职能边界：**服务治理** 和 **请求可靠传输**\
The concept of the service mesh as a separate layer is tied to the rise of the cloud native application. In the cloud native model, a single application might consist of hundreds of services; each service might have thousands of instances; and each of those instances might be in a constantly-changing state as they are dynamically scheduled by an orchestrator like Kubernetes. Not only is service communication in this world incredibly complex, it’s a pervasive and fundamental part of runtime behavior. Managing it is vital to ensuring end-to-end performance and reliability\
翻译：随着云原生应用的崛起，Service Mesh 逐渐成为一个独立的基础设施层。**在云原生模型里，一个应用可以由数百个服务组成，每个服务可能有数千个实例，而每个实例可能会持续地发生变化。服务间通信不仅异常复杂，而且也是运行时行为的基础**。管理好服务间通信对于保证端到端的性能和可靠性来说是非常重要的

单体架构-》模块化（进程内，函数调用）-》服务化（跨进程，api调用）-》微服务化（跨进程跨网络，服务数爆炸，服务治理成为必须）——》service mesh（解耦业务逻辑和服务间网络通讯）

**康威定律**：设计系统的架构受制于产生这些设计的组织沟通的结构\
**银弹理论**：没有任何一种技术或管理上的进步，能够极大地提升生产效率。引申到软件开发领域，即没有任何一种技术，可以完美地解决软件开发中的问题\
**墨菲定律**：当你认为可能出问题，那就一定会出问题\

微服务架构面临的最大痛点：**服务间网络通讯问题**\
why是网络通讯？根据分布式计算中的8个谬论\
1.网络是可靠的（不可靠）
2.网络延迟是0（有延迟，丢包）
3.网络带宽是无限的（带宽可能阻塞）
4.网络是安全的（不安全）
5.网络拓扑从不改变
6.只有一个管理员
7.传输成本是0
8.网络是同构的

Service Mesh 又称为第二代微服务架构，其解决了第一代微服务架构什么问题？\
1.语言绑定（组件库一般都是基于某个语言）
2.应用侵入性高（同一个进程）

**Service Mesh的演进过程**\
1.业务逻辑和网络通讯逻辑耦合在一起 ，问题：**不同的地方需要重复实现网络通讯逻辑**——》 
2.引入公共库来负责网络控制逻辑，和业务逻辑解耦（比如spring cloud提供的组件） 好处：解耦，消除重复；问题：人力和时间成本（需要花时间学习以及维护）、语言绑定（组件库一般都是基于某个语言），应用侵入性高（同一个进程）——》
3.边车模式（sidecar）：应用旁边单独部署的网络代理，负责处理网络相关的逻辑

**Service Mesh  ——》 Service Mesh 2**\
在data plane（所有的sidecar组合）基础上增加了control plane\
**data plane(数据平面)**：负责接收或转发系统中每一个数据包或请求，提供服务发现、健康检查、路由、负载均衡、流量控制、安全、监控等一些列跟服务间数据通信有关的功能；\
**control plane（控制平面）**：为在网格中运行的数据平面**提供策略和配置**，不接收系统中任何数据包或请求,也可以对接各种服务发现机制(如K8S服务发现)。

**Service Mesh和k8s的关系**：
k8s主要是为了解决容器的编排和调度问题，本质上是管理应用生命周期（调度器），对service mesh的实现提供支持和帮助，pod是k8s最小的调度单位，pod天生支持多容器的部署，因此为植入sidecar提供了便利，为service mesh的部署提供了非常大的支持\
Service Mesh主要是为了解决服务间网络通信的问题，本质上是管理服务通信（代理）

**Service Mesh和API网关的区别**：
API网关是部署在应用边界的，并没有侵入到应用内部，主要功能是对内部API进行一个聚合和抽象，以方便外部进行调用
功能有重叠，但角色不一样，Service Mesh在应用内，API网关在应用之上（边界）

Service Mesh的技术标准
（1）UDPA（Universal data plane API）:统一的数据平面API，主要是为不同的数据平面提供一个统一的API，方便应用无缝的接入，不同的数据平面有很多比如Envoy、Linkerd等，他们的接入标准是不一样的；
（2）SMI（Service Mesh Interface）

**RPC（Remote Procedure Call）**/
先来看一下本地方法调用的时候会发生什么

// 调用者（Caller）      ： main()\
// 被调用者（Callee）      ： println()\
// 调用点（Call Site）   ： 发生方法调用的指令流位置\
// 调用参数（Parameter） ： 由Caller传递给Callee的数据，即“hello world”\
// 返回值（Retval）      ： 由Callee传递给Caller的数据，如果方法正常完成，返回值是void，否则是对应的异常\
public static void main(String[] args) {\
  System.out.println(“hello world”);\
}

1.**传递方法参数**：将字符串 hello world 的引用压栈;\
2.**确定方法版本**：根据 println() 方法的签名，确定它的执行版本其实并不是一个简单的过程，不管是编译时的静态解析也好，还是运行时的动态分派也好，程序都必须根据某些语言规范中明确定义的原则，找到明确的被调用者 Callee。这里的“明确”是指唯一的一个 Callee，或者有严格优先级的多个 Callee，比如不同的重载版本。我曾在《深入理解 Java 虚拟机》中用一整章介绍过这个过程。如果你感兴趣的话，可以去深入了解一下;\
3.**执行被调方法**：从栈中获得 Parameter，以此为输入，执行 Callee 内部的逻辑。
4.返回执行结果：将 Callee 的执行结果压栈，并将指令流恢复到 Call Site 处，继续向下执行。

接下来，我们就需要考虑一下，当 println() 方法不在当前进程的内存地址空间中，会出现什么问题。不难想到，此时至少面临两个直接的障碍：\
1.**第一个障碍**：前面的第一步和第四步所做的传递参数、传回结果都依赖于栈内存的帮助，如果 Caller 与 Callee 分属不同的进程，就不会拥有相同的栈内存，那么在 Caller 进程的内存中将参数压栈，对于 Callee 进程的执行毫无意义;\
2.**第二个障碍**：第二步的方法版本选择依赖于语言规则的定义，而如果 Caller 与 Callee 不是同一种语言实现的程序，方法版本选择就将是一项模糊的不可知行为;

尽管调用远程方法和调用本地方法只有两字之差，但若要兼顾简单、透明、性能、正确、鲁邦和一致等特点，两者的复杂度就完全不可同日而语了。远程二字会带来网络环境下的各种新问题，比如
* 远程的服务在哪里（服务发现问题）
* 有多少个访问哪个（路由问题）
* 网络出现分区、超时或者服务出错怎么办（熔断、限流、隔离、降级等问题）
* 方法的参数和返回结果如何表示（序列化与反序列化问题）
* 数据如何传输（传输协议问题）
* 服务权限如何管理（认证、授权问题）
* 如何保证通信安全（网络安全问题）
* 如何令调用不同机器的服务返回相同的结果（分布式数据一致性问题）

**RPC 的定义**：RPC 是一种语言级别的通讯协议，它允许运行于一台计算机上的程序以某种管道作为通讯媒介（即某种传输协议的网络），去调用另外一个地址空间（通常为网络上的另外一台计算机）

所有流行过的 RPC 协议，都不外乎通过各种手段来解决三个基本问题：\
1.**如何表示数据（序列化与反序列化）**:\
**这里的数据包括了传递给方法的参数，以及方法的返回值**。无论是将参数传递给另外一个进程，还是从另外一个进程中取回执行结果，都会涉及应该如何表示的问题
针对进程内的方法调用，我们使用程序语言内置的和程序员自定义的数据类型，就很容易解决数据表示的问题了。而远程方法调用，则可能面临交互双方分属不同程序语言的情况。即使是只支持同一种语言的 RPC 协议，在不同硬件指令集、不同操作系统下，也完全可能有不一样的表现细节，比如数据宽度、字节序的差异等
行之有效的做法，是**将交互双方涉及的数据，转换为某种事先约定好的中立数据流格式来传输，将数据流转换回不同语言中对应的数据类型来使用**。这其实就是**序列化与反序列化**\

每种 RPC 协议都应该有对应的序列化协议，比如
ONC RPC 的External Data Representation 
（XDR）CORBA 的Common Data Representation（CDR）
Java RMI 的Java Object Serialization Stream Protocol
gRPC 的Protocol Buffers
Web Service 的XML Serialization
众多轻量级 RPC支持的JSON Serialization

2.**如何传输数据（通讯协议）**:\
准确地说，如何传递数据是**指如何通过网络，在两个服务 Endpoint 之间相互操作、交换数据**。这里“传递数据”通常指的是应用层协议，实际传输一般是基于标准的 TCP、UDP 等传输层协议来完成的
两个服务交互不是只扔个序列化数据流来表示参数和结果就行了，诸如异常、超时、安全、认证、授权、事务等信息，都可能存在双方交换信息的需求
在计算机科学中，专门有一个“Wire Protocol”，用来表示两个 Endpoint 之间交换这类数据的行为。常见的 Wire Protocol 有以下几种：
Java RMI 的Java Remote Message Protocol（JRMP，也支持RMI-IIOP）
CORBA 的Internet Inter ORB Protocol（IIOP，是 GIOP 协议在 IP 协议上的实现版本）
DDS 的Real Time Publish Subscribe Protocol（RTPS）
Web Service 的Simple Object Access Protocol（SOAP）
如果要求足够简单，双方都是 HTTP Endpoint，直接使用 HTTP 也可以（如 JSON-RPC）

3.**如何表示方法**:\
“如何表示方法”，这在本地方法调用中其实也不成问题，因为编译器或者解释器会根据语言规范，把调用的方法转换为进程地址空间中方法入口位置的指针

不过一旦考虑到不同语言，这件事儿又麻烦起来了，因为每门语言的方法签名都可能有所差别，所以，针对“如何表示一个方法”和“如何找到这些方法”这两个问题，我们还是得有个统一的标准。这个标准做起来其实可以很简单：只要给程序中的每个方法，都规定一个通用的又绝对不会重复的编号；在调用的时候，直接传这个编号就可以找到对应的方法。这种听起来无比寒碜的办法，还真的就是 DCE/RPC 最初准备的解决方案。

虽然最后，DCE 还是弄出了一套跟语言无关的接口描述语言（Interface Description Language，IDL），成为了此后许多 RPC 参考或依赖的基础（如 CORBA 的 OMG IDL），但那个唯一的“绝不重复”的编码方案UUID，却意外地流行了起来，已经被广泛应用到了程序开发的方方面面。

这类用于表示方法的协议还有：
* Android 的Android Interface Definition Language（AIDL）
* CORBA 的OMG Interface Definition Language（OMG IDL）
* Web Service 的Web Service Description Language（WSDL）
* JSON-RPC 的JSON Web Service Protocol（JSON-WSP）

一个RPC框架的关键技术分为两个：\
1、传输协议\
2、序列化协议

传输协议包含: 如著名的 [gRPC](grpc / grpc.io) 使用的 http2 协议，也有如dubbo一类的自定义报文的tcp协议

序列化协议包含: 如基于文本编码的 xml/json，也有二进制编码的 protobuf hessian等

**web services**\
传输协议：soap\
序列化协议：xml

**restful API**\
传输协议：http\
序列化协议：text（xml/json）

**gRPC**\
传输协议：http/2\
序列化协议：protocol buffer

影响序列化性能的关键因素
* 序列化后的码流大小（网络带宽的占用）；
* 序列化的性能（CPU资源占用）；
* 是否支持跨语言（异构系统的对接和开发语言切换）

常用序列化方式
* Java原生序列化：Java类通过实现Serializable接口来实现该类对象的序列化，这个接口非常特殊，没有任何方法，只起标识作用.Java序列化保留了对象类的元数据（如类、成员变量、继承类信息等），以及对象数据等，兼容性最好，但不支持跨语言，而且性能一般。
* C#原生序列化：
* JSON：数据文本存储，解析效率一般
* XML：数据文本存储，解析效率慢
* Protocol Buffer：数据二进制存储

同XML相比，Protobuf的优势在于高性能，它以高效的二进制存储方式比XML小3到10倍，快20到100倍，原因在于：
* ProtoBuf序列化后所生成的二进制消息非常紧凑（消息大小只需要XML的1/10 ~ 1/3）
* ProtoBuf封解包过程非常简单快速（解析速度比XML快20 ~ 100倍）

**Rpc VS Restful**

很多人都会拿 REST 来跟 RPC 对比优劣，其实，无论是思想上、概念上，还是使用范围上，REST 与 RPC 都不完全一样，它们在本质上并不是同一个类型的东西

REST 与 RPC 在思想上存在差异的核心，是抽象的目标不一样，也就是面向资源的编程思想与面向过程的编程思想之间的区别

二者在概念上的不同，是指 REST 并不是一种远程服务调用协议，甚至我们可以把定语也去掉，它就不是一种协议。REST 只能说是一种风格，而不是规范、协议，并且能完全达到 REST 所有指导原则的系统，也是很少见的

至于使用范围上，REST 与 RPC 作为主流的两种远程调用方式，在使用上确实有重合之处
1.对于重视远程服务调用效率的应用场景，就基本上已经排除了 REST 应用得最多的供浏览器端消费的远程服务。因为以浏览器作为前端，对于传输协议、序列化器这两点都没有什么选择权，哪怕想要更高效率也有心无力
2.在移动端、桌面端或者分布式服务端的节点之间通讯这一块，REST 虽然照样有宽阔的用武之地，只要支持 HTTP 就可以用于任何语言之间的交互，不过使用 REST 的前提是网络没有成为性能上的瓶颈。但是在需要追求传输效率的场景里，REST 提升传输效率的潜力有限，死磕 REST 又想要好的网络性能，一般不会有好的效果
3.，对于追求简化调用的场景，我在前面提到的浏览器端就属于这一类的典型，在众多 RPC 里，也就 JSON-RPC 有机会与 REST 竞争，其他 RPC 协议与框架，哪怕是能够支持 HTTP 协议，哪怕提供了 JavaScript 版本的客户端（如 gRPC-Web），也只是具备前端使用的理论可行性，很少能看到有实际项目把它们真的用到浏览器上的

理解REST
REST（英文：Representational State Transfer，简称REST） 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。理论上REST架构风格并不是绑定在HTTP上，但是REST本身受Web技术的影响很深， 目前HTTP是唯一与REST相关的实例。咱们来看看需要满足哪些约束条件和原则:

资源设计规则：
1.不用大写；
2.用中杠-不用下杠_；
3.用名词不用动词；
4.URI中的名词表示资源集合，使用复数形式;
动作设计规则：
1.GET（SELECT）：从服务器取出资源（一项或多项）。
2.POST（CREATE）：在服务器新建一个资源。
3.PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。
4.PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。
5.DELETE（DELETE）：从服务器删除资源。
返回结果规则：
与HTTP协议标准基本没有新的约束。要注意content-type的accept，包含accept-encoding

通过上面的约束条件和原则咱们来总结一下为什么叫REST："资源"是一种信息实体，它可以有多种外在表现形式。我们把"资源"具体呈现出来的形式，叫做它的"表现层"（Representation）。
互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生"状态转化"（State Transfer）。而这种转化是建立在表现层之上的，所以就是"表现层状态转化”
超文本(HyperText)：能够对操作进行判断和响应的文本
超媒体(HyperMedia):能够对操作进行判断和响应的图像、视频、音频等

关键概念：
（1）资源（Resource）：：譬如你现在正在阅读一篇名为《REST设计风格》的文章，这篇文章的内容本身（你可以将其理解为蕴含的信息、数据）称之为“资源”。无论你是通过阅读购买的图书、浏览器上的网页还是打印出来的文稿，无论是在电脑屏幕上阅读还是在手机上阅读，尽管呈现的样子各不相同，但其中的信息是不变的，你所阅读的仍是同一份“资源”；
（2）表征（Representation）：：当你通过浏览器阅读此文章时，浏览器会向服务端发出“我需要这个资源的HTML格式”的请求，服务端向浏览器返回的这个HTML就被称为“表征”，你也可以通过其他方式拿到本文的PDF、Markdown、RSS等其他形式的版本，它们同样是一个资源的多种表征。可见“表征”是指信息与用户交互时的表示形式，这与我们软件分层架构中常说的“表示层”（PresentationLayer）的语义其实是一致的。
（3）状态（State）:：当你读完了这篇文章，想看后面是什么内容时，你向服务端发出“给我下一篇文章”的请求。但是“下一篇”是个相对概念，必须依赖“当前你正在阅读的文章是哪一篇”才能正确回应，这类在特定语境中才能产生的上下文信息被称为“状态”。我们所说的有状态（Stateful）抑或是无状态（Stateless），都是只相对于服务端来说的，服务端要完成“取下一篇”的请求，要么自己记住用户的状态，如这个用户现在阅读的是哪一篇文章，这称为有状态；要么由客户端来记住状态，在请求的时候明确告诉服务端，如我正在阅读某某文章，现在要读它的下一篇，这称为无状态。
（4）转移（Transfer）：无论状态是由服务端还是由客户端来提供，“取下一篇文章”这个行为逻辑只能由服务端来提供，因为只有服务端拥有该资源及其表征形式。服务端通过某种方式，把“用户当前阅读的文章”转变成“下一篇文章”，这就被称为“表征状态转移”
（5）统一接口（Uniform Interface）:上面说的服务端“通过某种方式”让表征状态转移，那具体是什么方式呢？如果你真的是用浏览器阅读本文电子版的话，请把本文滚动到结尾处，右下角有下一篇文章的URI超链，击它让页面跳转到下一篇，就是所谓“某种方式”的其中一种方式。任何人都不会对点击超链接网页出现跳转感到奇怪，但你细想一下，URI的含义是统一资源标识符，是一个名词，如何能表达出“转移”动作的含义呢？答案是HTTP协议中已经提前约定好了一套“统一接口”，它包括GET、HEAD、POST、PUT、DELETE、TRACE、OPTIONS七种基本操作，任何一个支持HTTP协议的服务器都会遵守这套规定，对特定的URI采取这些操作，服务器就会触发相应的表征状态转移。
（6）超文本驱动（Hypertext Driven）：尽管表征状态转移是由浏览器主动向服务器发出请求所引发的，该请求导致了“在浏览器屏幕上显示出了下一篇文章的内容”的结果。但是，我们都清楚这不可能真的是浏览器的主动意图，浏览器是根据用户输入的URI地址来找到网站首页，读取服务器给予的首页超文本内容后，浏览器再通过超文本内部的链接来导航到这篇文章，阅读结束时，也是通过超文本内部的链接再导航到下一篇。浏览器作为所有网站的通用的客户端，任何网站的导航（状态转移）行为都不可能是预置于浏览器代码之中，而是由服务器发出的请求响应信息（超文本）来驱动的。这点与其他带有客户端的软件有十分本质的区别，在那些软件中，业务逻辑往往是预置于程序代码之中的，有专门的页面控制器（无论在服务端还是在客户端中）来驱动页面的状态转移
（7）自描述消息（SelfDescriptive Message）：由于资源的表征可能存在多种不同形态，在消息中应当有明确的信息来告知客户端该消息的类型以及应如何处理这条消息。一种被广泛采用的自描述方法是在名为“ContentType”的HTTP Header中标识出互联网媒体类型（MIMEtype），譬如“ContentType:application/json;charset=utf8”说明该资源会以JSON的格式来返回，请使用UTF8字符集进行处理

一套理想的、完全满足REST风格的系统应该满足以下六大原则:
（1）客户端与服务端分离（Client-Server)：将用户界面所关注的逻辑和数据存储所关注的逻辑分离开来，有助于提高用户界面的跨平台的可移植性，也越来越受到广大开发者所认可，以前完全基于服务端控制和渲染（如JSF这类）框架的实际用户已甚少，而在服务端进行界面控制（Controller），通过服务端或者客户端的模板渲染引擎来进行界面渲染的框架（如Struts、SpringMVC这类）也受到了颇大冲击。这一点与REST可能关系并不大，前端技术（从ES规范，到语言实现，再到前端框架等）在近年来的高速发展，使得前端表达能力大幅度加强才是真正的幕后推手。由于前端的日渐强势，现在还流行起由前端代码反过来驱动服务端进行渲染的SSR（ServerSideRendering）技术，在Serverless、SEO等场景中已经占领了一席之地。
（2）无状态（stateless）:无状态是REST的一条核心原则，部分开发者在做服务接口规划时，觉得REST风格的服务怎么设计都感觉别扭，很可能的一个原因是服务端持有比较重的状态。REST希望服务端不用负责维护状态，每一次从客户端发送的请求中，应包括所有必要的上下文信息，会话信息也由客户端负责保存维护，服务端只依据客户端传递的状态来执行业务处理逻辑，驱动整个应用的状态变迁。客户端承担状态维护职责以后，会产生一些新的问题，譬如身份认证、授权等可信问题，它们都应有针对性的解决方案[1]。但必须承认的是，目前大多数系统都达不到这个要求，且越复杂、越大型的系统越是如此。服务端无状态可以在分布式计算中获得非常高价值的回报，但大型系统的上下文状态数量完全可能膨胀到客户端无法承受的程度，在服务端的内存、会话、数据库或者缓存等地方持有一定的状态成为一种事实上存在，并将长期存在、被广泛使用的主流方案；
（3）可缓存（Cacheability）:无状态服务虽然提升了系统的可见性、可靠性和可伸缩性，但降低了系统的网络性。“降低网络性”的通俗解释是某个功能使用有状态的设计时只需要一次（或少量）请求就能完成，使用无状态的设计时则可能会需要多次请求，或者在请求中带有额外冗余的信息。为了缓解这个矛盾，REST希望软件系统能够如同万维网一样，允许客户端和中间的通信传递者（譬如代理）将部分服务端的应答缓存起来。当然，为了缓存能够正确地运作，服务端的应答中必须直接或者间接地表明本身是否可以进行缓存、可以缓存多长时间，以避免客户端在将来进行请求的时候得到过时的数据。运作良好的缓存机制可以减少客户端、服务端之间的交互，甚至有些场景中可以完全避免交互，这就进一步提高了性能。
（4）分层系统（Layered System）:这里所指的分层并不是表示层、服务层、持久层这种意义上的分层，而是指客户端一般不需要知道是否直接连接到了最终的服务器，抑或连接到路径上的中间服务器。中间服务器可以通过负载均衡和共享缓存的机制提高系统的可扩展性，这样也便于缓存、伸缩和安全策略的部署。该原则的典型应用是内容分发网络（ContentDistributionNetwork，CDN）。如果你是通过网站浏览到这篇文章的话，你所发出的请求一般（假设你在中国境内的话）并不是直接访问位于GitHubPages的源服务器，而是访问了位于国内的CDN服务器，但作为用户，你完全不需要感知到这一点。
（5）统一接口（Uniform Interface）:这是REST的另一条核心原则，REST希望开发者面向资源编程，希望软件系统设计的重点放在抽象系统该有哪些资源，而不是抽象系统该有哪些行为（服务）上。这条原则你可以类比计算机中对文件管理的操作来理解，管理文件可能会涉及创建、修改、删除、移动等操作，这些操作数量是可数的，而且对所有文件都是固定、统一的。如果面向资源来设计系统，同样会具有类似的操作特征，由于REST并没有设计新的协议，所以这些操作都借用了HTTP协议中固有的操作命令来完成。
统一接口也是REST最容易陷入争论的地方，基于网络的软件系统，到底是面向资源合适，还是面向服务更合适，这个问题恐怕在很长时间里都不会有定论，也许永远都没有。但是，已经有一个基本清晰的结论是：面向资源编程的抽象程度通常更高。抽象程度高带来的坏处是距离人类的思维方式往往会更远，而好处是通用程度往往会更好。用这样的语言去诠释REST，还是有些抽象，下面以一个例子来说明：譬如，对于几乎每个系统都有的登录和注销功能，如果你理解成登录对应于login()服务，注销对应于logout()服务这样两个独立服务，这是“符合人类思维”的；如果你理解成登录是PUTSession，注销是DELETESession，这样你只需要设计一种“Session资源”即可满足需求，甚至以后对Session的其他需求，如查询登录用户的信息，就是GETSession而已，其他操作如修改用户信息等也都可以被这同一套设计囊括在内，这便是“抽象程度更高”带来的好处。
（6）按需代码（Code-on-Demand）:按需代码被Fielding列为一条可选原则。它是指任何按照客户端（譬如浏览器）的请求，将可执行的软件程序从服务端发送到客户端的技术。按需代码赋予了客户端无须事先知道所有来自服务端的信息应该如何处理、如何运行的宽容度。举个具体例子，以前的JavaApplet技术，今天的WebAssembly等都属于典型的按需代码，蕴含着具体执行逻辑的代码是存放在服务端，只有当客户端请求了某个JavaApplet之后，代码才会被传输并在客户端机器中运行，结束后通常也会随即在客户端中被销毁。将按需代码列为可选原则的原因并非是它特别难以达到，更多是出于必要性和性价比的实际考虑。

REST提出以资源为主体的服务设计风格，可以带来不少好处
（1）降低服务接口的学习成本：统一接口是REST的重要标志，它将对资源的标准操作都映射到标准的HTTP方法上去，这些方法对于每个资源的用法都是一致的，语义都是类似的，不需要刻意去学习，更不需要有诸如IDL之类的协议存在；
（2）资源天然具有集合与层次结构：以方法为中心抽象的接口，由于方法是动词，逻辑上决定了每个接口都是互相独立的；但以资源为中心抽象的接口，由于资源是名词，天然就可以产生集合与层次结构；
（3）REST绑定于HTTP协议：面向资源编程不是必须构筑在HTTP之上，但REST是，这是缺点，也是优点。因为HTTP本来就是面向资源设计的网络协议，纯粹只用HTTP（而不是SOAPoverHTTP那样再构筑协议）带来的好处是无须考虑RPC中的WireProtocol问题，REST将复用HTTP协议中已经定义的概念和相关基础支持来解决问题。HTTP协议已经有效运作了三十年，其相关的技术基础设施已是千锤百炼，无比成熟。而坏处自然是，当你想去考虑那些HTTP不提供的特性时，便会彻底束手无策；

以上列举了一些面向资源编程的优点，但非要证明它比面向过程、面向对象编程更优秀，是否选用REST的API设计风格，需要结合你的需求场景、你团队的设计和开发人员是否能够适应面向资源的思想来设计软件来权衡。


RMM（Richardson Maturity Model）
·第0级（TheSwampofPlainOldXML）：完全不RES
第1级（Resources）：开始引入资源的概念
·第2级（HTTPVerbs）：引入统一接口，映射到HTTP协议的方法上
·第3级（HypermediaControls）：超媒体控制，在本文里面的说法是“超文本驱动”，在Fielding论文里的说法是“HypertextAsTheEngineOfApplicationState，HATEOAS”，其实都是指同一件事情
