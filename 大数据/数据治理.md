## **主数据**
企业数据6层模型：
- 业务审计数据
- 业务活动数据
- 业务结构数据
- 企业结构数据
- 参考（引用）数据
- 元数据

其中属于主数据范畴的包括：
- 业务结构数据
- 企业结构数据
- 参考（引用）数据

企业主数据是用来描述企业核心业务实体的数据，具有高业务价值，可以在企业内跨越各个业务部门被重复使用的数据，并且存在于多个异构的应用系统中

企业主数据可以包括很多方面，除了常见的客户主数据之外，不同行业的客户还可能拥有其他各种类型的主数据

主数据定义企业核心业务对象，主数据一旦被记录到数据库中，需要经常对其进行维护，从而确保其时效性和准确性；主数据还包括关系数据，用以描述主数据之间的关系

**集成、共享、数据质量、数据治理是主数据管理的四大要素**，主数据管理要做的就是从企业的多个业务系统中整合最核心的、最需要共享的数据（主数据），集中进行数据的清洗和丰富，并且以服务的方式把统一的、完整的、准确的、具有权威性的主数据分发给全企业范围内需要使用这些数据的操作型应用和分析型应用，包括各个业务系统、业务流程和决策支持系统等。

### **主数据 VS 数据仓库 区别**
- 处理类型不同：主数据管理 (MDM) 系统是偏交易型的系统，它为各个业务系统提供联机交易服务；而数据仓库是属于分析型的系统，面向的是分析型的应用，是在大量历史交易数据的基础上进行多维分析
- 实时性不同：与传统的数据仓库方案的批量ETL方式不同，主数据管理系统在数据初始加载阶段要使用ETL，但在后续运行中要大量依赖实时整合的方式来进行主数据的集成和同步；
- 数据量不同：数据仓库存储的是大量的历史数据和各个维度的汇总数据，可能会是海量的

### **主数据 VS ODS 区别**
二者存储的数据内容是全然不同的，主数据管理系统中不存储交易数据(即业务活动数据)

### **数据运营层（ODS）**

* ODS：Operation Data Store 数据准备区，也称为贴源层。数据仓库源头系统的数据表通常会原封不动的存储一份，这称为ODS层，是后续数据仓库加工数据的来源。
* ODS层数据的来源方式：
    * 业务库
            * 经常会使用sqoop来抽取，例如每天定时抽取一次。
            * 实时方面，可以考虑用canal监听mysql的binlog，实时接入即可。
    * 埋点日志
            * 日志一般以文件的形式保存，可以选择用flume定时同步
            * 可以用spark streaming或者Flink来实时接入
            * kafka也OK
            * 消息队列：即来自ActiveMQ、Kafka的数据等。

### **数据仓库层（DW）**
DW数据分层，由下到上为DWD，DWB，DWS
* DWD：data warehouse details 细节数据层，是业务层与数据仓库的隔离层。主要对ODS数据层做一些数据清洗和规范化的操作。
    * 数据清洗：去除空值、脏数据、超过极限范围的
* DWB：data warehouse base 数据基础层，存储的是客观数据，一般用作中间层，可以认为是大量指标的数据层。
* DWS：data warehouse service 数据服务层，基于DWB上的基础数据，整合汇总成分析某一个主题域的服务数据层，一般是宽表。用于提供后续的业务查询，OLAP分析，数据分发等。
    * 用户行为，轻度聚合
    * 主要对ODS/DWD层数据做一些轻度的汇总。

### **数据服务层/应用层（ADS）**
* ADS：Application Data Service应用数据服务，该层主要是提供数据产品和数据分析使用的数据，一般会存储在ES、mysql等系统中供线上系统使用。
    * 我们通过说的报表数据，或者说那种大宽表，一般就放在这里

### **传统数据仓库建模方法论**
比尔.恩门提出的建模方法自顶向下（这里的顶是指数据的来源，在传统数据仓库中，就是各个业务数据库），基于业务中各个实体以及实体之间的关系，构建数据仓库
金博尔建模与恩门正好相反，是一种自底向上的模型设计方法，从数据分析的需求出发，拆分维度和事实
比尔.恩门建模因为是从数据源开始构建，构建成本比较高，适用于应用场景比较固定的业务。金博尔建模由于是从分析场景出发，适用于变化速度比较快的业务

事实表、纬度表、宽表、拉链表、缓慢变化维、数据地图、血缘关系

大数据平台的概念，就是为了提高数据研发的效率，降低数据研发的门槛，让数据能够在一个设备流水线上快速地完成加工。大数据平台是面向数据研发场景的，覆盖数据研发的完整链路的数据工作台。

Hive、Spark、Flink、Impala 提供了大数据计算引擎：
Hive、Spark 主要解决离线数据清洗、加工的场景，目前，Spark 用得越来越多，性能要比 Hive 高不少；
Flink 主要是解决实时计算的场景；
Impala 主要是解决交互式查询的场景
数据存储在 HDFS、Kudu 和 HBase 系统内：
HDFS 不可更新，主要存全量数据；
HBase 提供了一个可更新的 KV，主要存一些维度表；
Kudu 提供了实时更新的能力，一般用在实时数仓的构建场景中

### **数据湖**
数据湖（Data Lake）是一个以原始格式存储数据的存储库或系统。企业可以基于 Hadoop 构建数据湖，将数据作为一种企业核心资产。

### **元数据管理（数据治理）**
元数据划为三类：数据字典、数据血缘和数据特征
- 数据字典描述的是数据的结构信息，包括表名、注释信息、每个表有哪些字段、字段的含义、字段的类型、表的产出任务等；
- 数据血缘是指一个表或字段是直接通过哪些表或字段加工而来，数据血缘一般会帮我们做影响分析和故障溯源
- 数据特征主要是指数据的属性信息，包括存储空间大小、访问热度、主题域、分层、表关联的指标等，可以通过标签的方式进行管理，允许用户基于标签类型和标签搜索表和字段

血缘采集，一般可以通过三种方式：
- 通过静态解析 SQL，获得输入表和输出表；
- 通过实时抓取正在执行的 SQL，解析执行计划，获取输入表和输出表；
- 通过任务日志解析的方式，获取执行后的 SQL 输入表和输出表。

第一种方式，面临准确性的问题，因为任务没有执行，这个 SQL 对不对都是一个问题。
第三种方式，血缘虽然是执行后产生的，可以确保是准确的，但是时效性比较差，通常要分析大量的任务日志数据

1.元数据中心必须支持多业务线、多租户
2.元数据中心必须要能够支持不同类型的数据源（比如 MySQL、Hive、Kudu 等），同时还要支持相同数据源的多个集群
3.元数据中心需要支持数据血缘的实时采集和高性能的查询。同时，还必须支持字段级别的血缘



### **数据地图：**
数据地图是基于元数据中心构建的一站式企业数据资产目录，可以看作是元数据中心的界面。数据开发、分析师、数据运营、算法工程师可以在数据地图上完成数据的检索，解决了“不知道有哪些数据？”“到哪里找数据？”“如何准确的理解数据”的难题


### **Shared-everything  vs  Shared-disk vs Shared-nothing**
数据存储的架构设计中有Shared Everthting、Shared Nothing和Shared Disk之分

Shared Everthting:一般是针对单个主机，完全透明共享CPU/MEMORY/IO，并行处理能力是最差的，典型的代表SQLServer
Shared Disk：各个处理单元使用自己的私有 CPU和Memory，共享磁盘系统。典型的代表 Oracle Rac， 它是数据共享，可通过增加节点来提高并行处理的能力，扩展能力较好。其类似于SMP（对称多处理）模式，但是当存储器接口达到饱和的时候，增加节点并不能获得更高的性能 
Shared Nothing：各个处理单元都有自己私有的CPU/内存/硬盘等，不存在共享资源，类似于MPP（大规模并行处理）模式，各处理单元之间通过协议通信，并行处理和扩展能力更好。典型代表DB2 DPF和 Hadoop ，各节点相互独立，各自处理自己的数据，处理后的结果可能向上层汇总或在节点间流转

PS：我们常说的 Sharding 其实就是Shared Nothing，它是把某个表从物理存储上被水平分割，并分配给多台服务器（或多个实例），每台服务器可以独立工作，具备共同的schema，比如MySQL Proxy和Google的各种架构，只需增加服务器数就可以增加处理能力和容量