### **SRE出现的背景**

很多不同类型、不同规模的企业 IT 团队，为了提升用户价值的交付效率，都在积极采用微服务、容器，以及其他的分布式技术和产品，而且也在积极引入像 DevOps 这样的先进理念

这些公司选择了正确的架构演进方向和交付理念，效率自然是提升了一大截，这时候你会发现，效率提升了，但挑战紧跟着也来了：在引入了这么多先进的技术和理念之后，这种复杂架构的系统稳定性很难得到保障，怎么办？这个问题其实不难回答，答案就是SRE

### **什么是SRE**

Google SRE 就是目前稳定性领域的最佳实践。也可以说，SRE 已经成为稳定性的代名词。其实，SRE 要做的事情并不神秘，我们每天做的监控告警、运维自动化、故障处理和复盘等工作，就是 SRE 的一部分

很多人想当然地认为，SRE 就是一个岗位，是一个角色，而且是无所不能的角色

其实，**SRE 是一套体系化的方法**，我们也只有用全局视角才能更透彻地理解它。从职能分工上，SRE 体系的建设绝不是单个岗位或单个部门就能独立完成的，必然要求有高效的跨团队组织协作才可以。不要想着设定一个 SRE 岗位，就能把稳定性的事情全部解决掉，这明显不现实。你应该从体系的角度出发，设置不同的职能岗位，同时还要有让不同角色有效协作的机制。SRE 是一个体系化工程，它需要协同多个部门、多项技术。

![SRE保障性规划图]()

### **SRE的目的**

就是提升稳定性。但是怎样才算提升了稳定性呢？

从业界稳定性通用的衡量标准看，有两个非常关键的指标：
- MTBF，Mean Time Between Failure，平均故障时间间隔；
- MTTR，Mean Time To Repair， 故障平均修复时间；

 从上面的SRE 稳定性保障规划图，你会发现我们把整个软件运行周期按照这两个指标分成了两段。通俗地说，**MTBF 指示了系统正常运行的阶段，而 MTTR 则意味着系统故障状态的阶段**。

如果想提升稳定性，就会有两个方向：
- **提升 MTBF**：也就是减少故障发生次数，提升故障发生间隔时长；
- **降低 MTTR**：故障不可避免，那就提升故障处理效率，减少故障影响时长；

从 SRE 稳定性保障规划图中，可以看出 MTTR 可以细分为 4 个指标：MTTI、MTTK、MTTF 和 MTTV

![MTTR四个细分指标]()

我们做的任何一件事情、开发的任何一套系统、引入的任何一个理念和方法论，有且只有一个目标，那就是“提升 MTBF，降低 MTTR”，也就是把故障发生时间的间隔变长，将故障影响的时间减少：
- 比如，在 Pre-MTBF 阶段（无故障阶段），我们要做好架构设计，提供限流、降级、熔断这些 Design-for-Failure 的服务治理手段，以具备故障快速隔离的条件；还可以考虑引入混沌工程这样的故障模拟机制，在线上模拟故障，提前发现问题；
- 在 Post-MTBF 阶段，也就是上一故障刚结束，开启新的 MTBF 阶段，我们应该要做故障复盘，总结经验，找到不足，落地改进措施等；
- 在 MTTI 阶段，我们就需要依赖监控系统帮我们及时发现问题，对于复杂度较高和体量非常大的系统，要依赖 AIOps 的能力，提升告警准确率，做出精准的响应；
- 同时 AIOps 能力在大规模分布式系统中，在 MTTK 阶段也非常关键，因为我们在这个阶段需要确认根因，至少是根因的范围；

### **系统可用性**

我们先来讨论一下系统可用性这个概念，因为系统可用性和我们建设 SRE 的目标强相关

目前业界有两种衡量系统可用性的方式，一个是时间维度，一个是请求维度
- **时间维度**：Availability = Uptime / (Uptime + Downtime)
- **请求维度**：Availability = Successful request / Total request

1. **时间维度**：

   时长维度，是从故障角度出发对系统稳定性进行评估，在真实的使用场景中，怎么样才算是可用时长，什么情况下又是不可用时长，这个是怎么定义的呢？

   这里就涉及到一个测量方法和判定方法的问题，包含三个要素：
   - 一个是衡量指标；
   - 第二个是衡量目标，达到什么目标是正常，达不到就是异常；
   - 但是单次测量不能说明问题，我们可以多次测量，所以第三个是影响时长，比如持续超过 12 小时

   对应到系统上，我们也会用一系列的标准和判定逻辑来说明系统是否正常。比如，系统请求状态码为非 5xx 的比例，也就是请求成功率低于 95%，已经连续超过 10 分钟，这时就要算作故障，那么 10 分钟就要纳入 Downtime（宕机时间），如果达不到这个标准，就不算作故障，只是算作一般或偶然的异常问题，这里同样有三个要素：
   - 衡量指标，系统请求状态码；
   - 衡量目标，非 5xx 占比，也就是成功率达到 95%；
   - 影响时长，持续 10 分钟

   因此，只有当问题达到一定影响程度才会算作故障，这时才会计算不可用时长，也就是上面公式中的 Downtime。同时，我们还要求一个周期内，允许的 Downtime，或者说是系统的“生病时间”是有限的，用这个有限时间来约束系统稳定性

   下面是我们常见的按时长维度统计的可用性对照表

   ![availability-downtime]()

   用时间维度统计可用性，最显著的问题就是，稳定性只与故障发生挂钩

   这样做会带来哪些问题？比如有一个系统，因为网络抖动，有短暂的几秒、十几秒，或者几分钟异常，但是后来系统自己恢复了，业务并没有中断，这时我们按照时长维度来判断，这肯定不会算作系统故障。但是如果这种短暂的影响频度非常高，一天来个 5、6 次，持续一两周，我们应该可以判定系统运行状况也是不正常的，可能不是故障，但肯定是不稳定了

   所以这种用时长维度来衡量系统稳定性的方式，其**主要缺点就是粒度不够精细**。这些小的异常问题和它们的影响，如果从更长的周期来看，也是有一定参考价值的

   这就需要第二种衡量方式了，也就是从请求维度来衡量系统可用性

2. **请求维度**：

   请求维度，是从成功请求占比的角度出发，对系统的稳定性进行评估

   假定我们的系统一天内有 100,000 次请求，我们期望的成功率至少是 95%，如果有 5001 次请求失败了，也就是成功率低于 95% 了，我们就认为系统运行状态是不正常的。
   
   请求维度的系统可用性同样包含三个关键要素：
   - 第一个衡量指标，请求成功率；
   - 第二个衡量目标，成功率达到 95% 才算系统运行正常；
   - 第三个是统计周期，比如一天、一周、一个月等等，我们是在一个统计周期内计算整体状况，而不是看单次的

### **设定系统稳定性目标要考虑的 3 个因素**

1. **成本因素**

   从理论上来说，肯定是 9 越多稳定性越好，但是相应付出的成本和代价也会更高。比如**为了更高的可用性，要有更多的冗余资源投入，甚至要做主备、双活甚至是多活**。如果一家公司的业务量和影响力都发展到一定程度，那这个成本不管多高都是必须要付出的。但是，肯定不是所有的公司都需要付出这么高的成本，而是要先考虑 ROI（回报率）。这时候就要看企业自身对成本压力的承担情况了

2. **业务容忍度**

   稳定性怎么设定，很大程度上还要取决于业务上的容忍度。
   
   对于核心业务或核心应用，比如电商的交易和支付系统，我们当然是希望成功率越高越好，一般对系统稳定性要求是“3 个 9”或“4 个 9”。因为这些系统一旦出问题，就会直接影响整个网站和公司的收益，这些都是钱，所以对稳定性要求必然就会提高。
   
   但是，对于非核心业务或应用，比如商品评论，商品评分等，或许“2 个 9”也能容忍。因为短时间的评论看不到，并不会对业务收入和用户体验造成太大的影响

3. **系统当前的稳定性状况**

   结合系统的实际情况，定一个合理的标准比定一个更高的标准会更重要

   这个合理的值应该怎么来定呢？建议是从系统现状入手，比如，如果系统可用性是低于 99% 的，那首先第一步是不是可以做到 99%，然后再争取做到 99.5%，再到 99.9%，一步一步朝着更高的标准迈进。同时，这样做也会更容易落地，因为你如果定一个太高的目标，又始终达不成，反而会打击到团队的自信心和积极性

总结一下

关于系统可用性，业界有两种计算方式，一种是时长维度，另一种是请求维度，这两种方式各有优劣。在 SRE 的实践中，会更多采用请求维度的统计方式，因为 SRE 关注的稳定性是系统的整体运行状态，而不仅仅只关注故障状态下的稳定性，在系统运行过程中的任何异常，都会被纳入稳定性的评估范畴中










